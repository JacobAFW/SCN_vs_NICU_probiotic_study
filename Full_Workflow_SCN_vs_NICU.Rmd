---
title: "Full_Workflow"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# About.

This document contains the workflow for the manuscript *BLANK_BLANK*, and is based on the workflow from the paper (Characterising the bacterial gut microbiome of probiotic-supplmented very-preterm infants)[https://github.com/JacobAFW/NICU_Microbiome_Study/blob/main/Complete_Workflow_NICU_Microbiome.pdf],and includes the bioinformatics pipeline to go from raw reads to interpretable abundances, based largely around this [DADA2](https://pubmed.ncbi.nlm.nih.gov/27508062/) workflow developed by *Callahan, et al.*, with removal of contamination with [MicroDecon](https://onlinelibrary.wiley.com/doi/full/10.1002/edn3.11), and the analysis using a combination of the packages [phyloseq](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0061217), [DESeq2](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-014-0550-8), [lme4](https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf) and more.

# Bioinformatics Pipeline.

## About.

Creating an ASV table from raw reads, using [DADA2](https://pubmed.ncbi.nlm.nih.gov/27508062/).

## Load required packages.

```{r, warning=F, message=F, results='hide'}
sapply(c("dada2", "phyloseq", "DECIPHER", "phangorn", "BiocManager", "BiocStyle", 
        "Biostrings", "ShortRead", "ggplot2", "gridExtra", "tibble", "tidyverse"), 
        require, character.only = TRUE)
```

## Read quality.

### Organise forward and reverse fastq filenames into own lists (check file format).
 - First define the file path to the directory containing the fastq files (we will use this several times).
 
```{r, warning=F, message=F}
path <-"Data"

fnFs <- sort(list.files(path, pattern = "_R1_001.fastq.gz", full.names = TRUE))

fnRs <- sort(list.files(path, pattern = "_R2_001.fastq.gz", full.names = TRUE))
```

### Extract sample names.

```{r, warning=F, message=F}
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
```

\newpage

### Check quality of Forward and Reverse Reads (used to define truncLen in filtering).

```{r, warning=F, fig.cap="Quality of forward reads.", message=F}
plotQualityProfile(fnFs[1:2])
```

```{r, warning=F, fig.cap="Quality of reverse reads.", message=F}
plotQualityProfile(fnRs[1:2])
```

### Assign names for filtered reads.

```{r, warning=F, message=F}
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))

filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
```

### Filter and trim the reads. 
 - Paremeters based on data and quality plots. 
 - `truncLean` defined by when quality plots begin to drop off, but ensuring it is large enough to maintain read overlap (=>20bp) downstream.
 - `trimLeft` is not needed as primers/barcodes already removed.
 - `maxEE = c(2,2)` is for filtering, where the higher the value the more relaxed filtering,allowing more reads to get through. 
 - Good quality data should allow for more stringent parameters (2 is stringent).
 - The number of reads filtered is checked. If reads are too low, can alter parameters.
 
```{r, warning=F, message=F}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen = c(280,200), 
                     trimLeft = c(16,21), 
                     maxN = 0, 
                     maxEE = c(2,2), 
                     truncQ = 2, 
                     rm.phix = TRUE,
                     compress = TRUE, 
                     multithread = FALSE)# windows can't support multithread
head(out)
```

## Infer sequence variants.

### Calculate Error Rates.
 - Error rates are used for sample ineference downstream.
 
```{r, warning=F, message=F, results='hide'}
errF <- learnErrors(filtFs, multithread = TRUE)

errR <- learnErrors(filtRs, multithread = TRUE)
```

### Plot error rates. 
 - Estimated error rates (black line) should be a good fit to observed rates (points) and error should decrease.
 
```{r, warning=F, fig.cap="Error rates for forward reads", message=F}
plotErrors(errF, nominalQ = TRUE)
```

```{r, warning=F, fig.cap="Error rates for reverse reads.", message=F}
plotErrors(errR, nominalQ = TRUE)
```

### Dereplication.
 - Combine indentical sequences into unique sequence bins.
 - Name the derep-class objects by the sample name.
 
```{r, warning=F, message=F}
derepFs <- derepFastq(filtFs, verbose = TRUE)

derepRs <- derepFastq(filtRs, verbose = TRUE)

names(derepFs) <- sample.names

names(derepRs) <- sample.names
```

### Sequence Inference.

```{r, warning=F, message=F, results='hide'}
dadaFs <- dada(derepFs, err = errF, multithread = F)

dadaRs <- dada(derepRs, err = errR, multithread = F)
```

### Inspect denoised data.

```{r, warning=F, message=F, results='hide'}
dadaFs[[1]]

dadaRs[[1]]
```

### Merge Paired Reads and inspect merged data.
 - Removes paired reads that do not perfectly overlap.
 - Arguments represent infered samples AND denoised reads.
 
```{r, warning=F, message=F, results='hide'}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose = TRUE)
```

## Construct amplicon sequence variance (ASV) table and remove chimeras.

### Construct ASV table.
 - Check dimentions and inspect distribution of sequence lengths.
 
```{r, warning=F, message=F, results='hide'}
seqtab <- makeSequenceTable(mergers)

dim(seqtab)

seqtab %>% 
  getSequences() %>% 
  nchar() %>% 
  table()

# SHOULD GET THE SAME OUTPUT AS: table(nchar(getSequences(seqtab)))
```

### Remove chimeras.

```{r, warning=F, message=F}
seqtab.nochim <- removeBimeraDenovo(seqtab, method = "consensus", 
                                    multithread = TRUE, verbose = TRUE)

rm(seqtab)
```

### Track reads through pipeline.

```{r, warning=F, message=F}
getN <- function(x) sum(getUniques(x))

track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), 
               sapply(mergers, getN), rowSums(seqtab.nochim))

colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")

rownames(track) <- sample.names

head(track)
rm(track)
```

## Contamination removal with *MicroDecon*.

```{r, warning=F, message=F}
library(microDecon)
```
 
### Read in metadata (needed for MicroDecon)

```{r}
Metadata  <- readxl::read_excel("Data/New_metadata.xlsx")
```

### Reformat data for *MicroDecon*.
 - **REFORMAT FUNCTION** for your data.
 - Transpose sequencing table (post chimera removal) and convert to a dataframe.
 - Reorder sequencing table by a prior grouping (days).
 - Move blank sample columns to the start of the sequencing table.
 - Turn row names into their own column as *MicroDecon* requires that the OTUs have a unique ID in column 1.
 
```{r}
wrangle_microdecon <- function(seqtab.nochim){
  
# transpose data
microdecon.df <- t(seqtab.nochim) %>%
  as.data.frame()

# a prior grouping
  Metadata_microdecon <- Metadata %>% 
  arrange(Date) %>% 
  select(Sample, Date) %>% # select key columns
  mutate(Sample = paste0("AM", Sample)) # add AM into cell values to be the same as the count table

microdecon.df <- microdecon.df %>% 
  relocate(any_of(Metadata_microdecon$Sample)) # rearrange the columns by the ordered metadata

# blanks to first columns
Metadata_microdecon <- Metadata %>% 
  filter(Type == "negative control") %>%  # filter for negative controls
  select(Sample, Type, Date) %>% 
  mutate(Sample = paste0("AM", Sample)) 

microdecon.df <- microdecon.df %>% 
  relocate(any_of(Metadata_microdecon$Sample)) %>% 
  tibble::rownames_to_column(var = "ID") # turn the rownames into the first column
}

microdecon.df <- wrangle_microdecon(seqtab.nochim)

rm(seqtab.nochim)
```


### Decontaminate data using `decon()`.

 - get the counts for each of the a priori groups for `numd.ind`, not including the blanks.
 
```{r}
numb_ind_vector <- Metadata %>% 
  filter(Type == "Microbiome") %>% # remove blanks
  group_by(Date) %>% 
  summarise(n()) %>% # get the counts for each date.
  select("n()") %>% 
  add_row("n()" = 35) %>% # 26 is the number of samples there are no metadata for.
  rename("n" = "n()")
```

 - `(ncol(microdecon.df) - 26) - (nrow(Metadata))` should be equal to 1 (ID column).
 - `numb.ind` is the number of columns for each priori grouping.
 - `taxa = F` as there is no taxonomy in the dataframe.
 
```{r, warning=F, message=F}
decontaminated <- decon(data = microdecon.df, numb.blanks = 7, 
                  numb.ind = numb_ind_vector$n, taxa = F)

rm(microdecon.df)
rm(numb_ind_vector)
```

#### Check *MicroDecon* Outputs.

```{r, eval=F, message=F}
decontaminated$decon.table
decontaminated$reads.removed
decontaminated$OTUs.removed
decontaminated$mean.per.group
decontaminated$sum.per.group
```

### Reformat decon.table.
 - Convert column 1 to row names.
 - Remove blank average column (1).
 - Save rownames as seperate vector to be added back, as row names are removed during apply().
 - Convert numeric values to integers (for downstream analysis).
 - Transpose data.
 
```{r, warning=F, message=F}
seqtab.microdecon <- decontaminated$decon.table %>% 
  remove_rownames() %>% 
  column_to_rownames(var = "ID") %>% 
  select(-1) %>% # remove mean blank
  as.matrix() %>% 
  t()

rm(decontaminated)
```

### Merging multiple sequence runs.
 
```{r, include=F}
# Reading in pilot data for rmd.
seqtab.NICU <- read.csv("FILEPATH", row.names = 1) %>%
  as.matrix() %>% 
  mergeSequenceTables(seqtab)
```

## Assign taxonomy.
 - With optional species addition (there is an agglomeration step downstream, so you can add species now for curiosities sake, and remove later for analysis).
 
```{r, warning=F, message=F}
taxa <- assignTaxonomy(seqtab.microdecon, "~/Aquaculture_Microbiome/SILVA/silva_nr_v132_train_set.fa.gz")

taxa.print <- taxa # Removes sequence rownames for display only
rownames(taxa.print) <- NULL
```

# Need to run species assignment on hpc
```{r}
write.csv(taxa, "taxa.csv")

taxa <- addSpecies(taxa, "~/Aquaculture_Microbiome/SILVA/silva_species_assignment_v132.fa.gz") 
```

### Calculate percentage of NA taxa
```{r}
sum(is.na(taxa))/prod(dim(taxa)) * 100

apply(taxa, 2, function(col)sum(is.na(col))/length(col)) * 100
```

# Preprocessing: Creating a Phyloseq Object.

## About.
Creating a [phyloseq](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0061217) object to be used for analysis, and create different objects to be used for different types of analysis downstream.

## Load required packages. 

```{r, warning=F, message=F, results='hide'}
sapply(c("caret", "pls", "e1071", "ggplot2", 
    "randomForest", "tidyverse", "ggrepel", "nlme", "devtools", 
    "reshape2", "PMA", "structSSI", "ade4","ggnetwork", 
    "intergraph", "scales", "readxl", "genefilter", "impute", 
    "phyloseq", "phangorn", "dada2", "DECIPHER", "gridExtra", "stringi", "janitor",), 
    require, character.only = TRUE)
```

## Import metadata.

```{r}
Metadata <- readxl::read_excel("Data/New_metadata.xlsx") %>% 
  select(-c(3, 18, 21)) %>% 
  add_column("Primary_Group" = "SCN", "Type" = "Discharge") %>% 
  rbind(
    readxl::read_excel("Data/Old_metadata.xlsx") %>% 
      separate(DOB, into = c("DOB", "Time"), sep = "\\s") %>% 
      mutate(DOB = as.Date(DOB)) %>% 
      select(1, 3:4, 9, 17:18, 20:35)
    ) 
```

## Constuct a phylogenetic tree (for Phyloseq object downstream, required for distance measures).
 - Peform multiple-allignment.
 - `pml` calculates the likelihood of a given tree, and then `optim.pml()` optimizes the tree topology and branch length for the selected model (GTR+G+I max tree).

```{r, warning=F, message=F, results='hide'}
seqs <- getSequences(seqtab.microdecon)

names(seqs) <- seqs 

alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA, verbose=FALSE)

phangAlign <- phyDat(as(alignment, "matrix"), type = "DNA")

fitGTR <- phangAlign %>%
  dist.ml() %>%
  NJ() %>%
  pml(data = phangAlign) %>%
  update(k = 4, inv = 0.2) %>%
  optim.pml(model = "GTR", optInv = TRUE, optGamma = TRUE, 
  rearrangement = "NNI", control = pml.control(trace = 0))

detach("package:phangorn", unload = TRUE) # conflicts downstream
```

## Constrcut the Phyloseq object.
 - Includes: metadata, ASV table, taxonomy table and phylogenetic tree.
 
```{r, warning=F, message=F, results='hide'}
ps <- phyloseq(otu_table(seqtab.microdecon, taxa_are_rows=FALSE), 
               sample_data(Metadata), 
               tax_table(taxa),
               phy_tree(fitGTR$tree))
```

## Wrangling the metadata.
 - And do some additional wrangling.
 - Convert chraracters to factors.

```{r, warning=F, message=F, results='hide'}
sample_data(ps) <- sample_data(ps) %>%
  unclass() %>%
  as.data.frame() %>%
  mutate_if(is.character, as.factor) %>%
  mutate("Sample" = ID) %>% # need to redo the rownames to save it back into the original ps object
  mutate(Sample = paste0("AM", Sample)) %>% 
  column_to_rownames("Sample") 
```

### Subset phyloseq object for data to be analyzed.

```{r, warning=F, message=F, results='hide'}
ps <- subset_samples(ps, Type == "Discharge")
```

## Filtering and normalisation.

### Taxonomy filtering.
 - Can check the number of phyla before and after transformation with `table(tax_table(ps)[, "Phylum"], exclude = NULL)`.
 - Remove features with ambiguous and NA phylum annotation.

```{r, warning=F, message=F, results='hide'}
ps1 <- subset_taxa(ps, !is.na(Phylum) & !Phylum %in% c("", "uncharacterized"))
```

#### Check percentages of NA values left
```{r}
sum(is.na(tax_table(ps1)))/prod(dim(tax_table(ps1))) * 100

apply(tax_table(ps1), 2, function(col)sum(is.na(col))/length(col)) * 100
```

### Prevelance filtering.
 - Using an unsupervised method (relying on the data in this experiment) explore the prevelance of features in the dataset.
 - Calculate the prevalence of each feature and store as a dataframe.
 - Add taxonomy and total read counts.
 
```{r, warning=F, message=F, results='hide'}
prevdf = apply(X = otu_table(ps1),
               MARGIN = ifelse(taxa_are_rows(ps1), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})

prevdf = data.frame(Prevalence = prevdf,
                    TotalAbundance = taxa_sums(ps1),
                    tax_table(ps1))
```

 - Plot the relationship between prevelance and total read count for each feature. This provides information on outliers and ranges of features.
 
```{r, warning=F, message=F, fig.cap="Scatterplot exploring the relationship between prevelance and abundance of phyla."}
prevdf %>%
  subset(Phylum %in% get_taxa_unique(ps1, "Phylum")) %>%
  ggplot(aes(TotalAbundance, Prevalence / nsamples(ps1),color=Phylum)) +
  geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 1) +  
  geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +  
  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position="none")
```

 - Define prevalence threshold based on the plot (~1% is standard) and apply to ps object (if prevelance is too low don't designate a threshold).
 
```{r, warning=F, message=F, results='hide'}
prevalenceThreshold = 0.01 * nsamples(ps1)

keepTaxa = rownames(prevdf)[(prevdf$Prevalence >= prevalenceThreshold)]

ps2 = prune_taxa(keepTaxa, ps1)
```

 - Explore the relationship on the filtered data set.
```{r, warning=F, message=F, fig.cap="Scatterplot exploring the relationship between prevelance and abundance of phyla on data passed through a prevalence threshold."}
prevdf %>%
  subset(Phylum %in% get_taxa_unique(ps2, "Phylum")) %>%
  ggplot(aes(TotalAbundance, Prevalence / nsamples(ps2),color=Phylum)) +
  geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 1) +  
  geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +  
  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position="none")
```

### Aggolmerate taxa.
 - Combine features that descend from the same genus as most species have not been identified due to the poor sequencing depth in 16S.
 - Can check how many genera would be present after filtering by running `length(get_taxa_unique(ps2, taxonomic.rank = "Genus"))`, and `ntaxa(ps3)` will give the number of post agglomeration taxa.
 
```{r, warning=F, message=F, results='hide'}
ps3 = tax_glom(ps2, "Genus", NArm = TRUE)
```

 - Create tree plots to observe pre and post agglomeration.
 
```{r, warning=F, message=F, fig.cap="Tree plots exploring the agglomeration of taxa at the genus level."}
grid.arrange(nrow = 1, 
    (plot_tree(ps2, method = "treeonly",
      ladderize = "left", title = "Before Agglomeration") +
      theme(plot.title = element_text(size = 15))), 
    (plot_tree(ps3, method = "treeonly",
      ladderize = "left", title = "Post Genus Agglomeration") +
      theme(plot.title = element_text(size = 15))))
```

### Normalisation.
 - Plot a refraction curve to see if total sum scaling will surfice.
 - Define colours and lines.
 - Step = step size for sample sizes in rarefaction curve.
 
```{r, warning=F, message=F}
vegan::rarecurve(t(otu_table(ps3)), step = 20, label = FALSE, main = "Rarefaction Curve", 
        col = c("black", "darkred", "forestgreen", "orange", "blue", "yellow", "hotpink"))
```

 - Perform total sum scaling on agglomerated dataset.
 
```{r, warning=F, message=F}
ps4 <- transform_sample_counts(ps3, function(x) x / sum(x))
```

 - Explore normalisation with violin plots.
 - Compares differences in scale and distribution of the abundance values before and after transformation.
 - Using arbitrary subset, based on Phylum = Firmicutes, for plotting (ie. can explore any taxa to observe transformation).
 
```{r, warning=F, message=F, fig.cap="Violin plots exploring of distribution of abundance in Firmicutes before and after normalisation of data. Annotation for x axis; A: Admission, D: Discharge & I: Intermediate."}
plot_abundance = function(physeq, Title = "Abundance", Facet = "Order", Color = "Phylum"){
    subset_taxa(physeq, Phylum %in% c("Firmicutes")) %>%
    psmelt() %>%
    subset(Abundance > 0) %>%
    ggplot(mapping = aes_string(x = "Type", y = "Abundance", color = Color, fill = Color)) +
      geom_violin(fill = NA) +
      geom_point(size = 1, alpha = 0.3, position = position_jitter(width = 0.3)) +
      facet_wrap(facets = Facet) + 
      scale_y_log10()+
      scale_x_discrete(labels = c("A", "D", "I", "NA")) +
      theme(legend.position="none") +
      labs(title = Title)
}

grid.arrange(nrow = 2, (plot_abundance(ps3, Title = "Abundance", Color = "Type")),
             plot_abundance(ps4, Title = "Relative Abundance", Color = "Type"))
```

 - Explore normalisation with tree plots.
 
```{r, warning=F, message=F, fig.cap="Tree plot exploring the normalised distribution of taxa between admission and discharge samples."}
plot_tree(ps4.NICU_no_na, size = "Abundance", color = "Type", 
    justify = "yes please", ladderize = "left") +
    labs(title = "Phylogenetic Tree and Relative Abundance") +
    scale_size_continuous(range = c(.5, 3))
```

# Data Exploration and Univariate Analysis.

## About.
This section again uses the [phyloseq](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0061217) package (along with several others) to explore the data using bar, violin and ordination plot. This then leads into a collection of univariate analyses, including; alpha and beta diversity, and also taxonomic differential abundance.

## Load required packages. 

```{r, warning=F, message=F, results='hide'}
sapply(c("BiocManager", "ggplot2", "ggforce", "vegan", "knitr", "dplyr", 
         "phyloseq", "phyloseqGraphTest", "igraph", "ggnetwork", "nlme", 
         "reshape2", "tidyverse", "plyr", "DESeq2", "sjPlot", "ggpubr", 
         "gridExtra", "grid", "gtable", "lazyeval"), require, character.only = TRUE)
```

## Taxanomic distribution.

### Bar charts
 - Use `plot_bar_auto()` function wrapped around phyloseq's `plot_bar()` to explore the distribution of taxa at the genus and phylum levels.
 - Subset transformed data (relative abundance) to only the top20 taxa.
 
```{r, warning=F, message=F, fig.cap="Bar plots of the taxonomic distribution (relative abundance) at phylum and genus levels.", results='hide'}
top20 <- names(sort(taxa_sums(ps4), decreasing=TRUE))[1:20]
ps.top20 <- prune_taxa(top20, ps4)

plot_bar_auto <- function(ps, taxonomy){
plot_bar(ps, fill = taxonomy) + 
    facet_wrap(~Date, scales = "free_x") + 
    labs(title = paste0("Level:", taxonomy), y = "Abundance") + 
    theme(legend.position = "bottom", legend.title = element_blank(), 
    axis.title.x = element_blank(), axis.text.x = element_blank(), 
    axis.ticks = element_blank())
}

plot_bar_auto(ps.top20, "Phylum")
```

### Calculate the number samples containing a given taxa by creating a `samples_with_taxa()` function.

 - The function takes the phyloseq object, taxonomy level and taxanomic name (with the later two as strings). 
 - It then gets the ASV name from the *phyloseq* `tax_table()` by filtering with *dply* and [*lazyeval*](https://cran.r-project.org/web/packages/lazyeval/index.html). ( *lazyeval* is needed because of two concepts;[non-standard evaluation](http://adv-r.had.co.nz/Computing-on-the-language.html) and [lazy evaluation](http://adv-r.had.co.nz/Functions.html#function-arguments).
 - `paste()` is then used to concatenate the ASVs and `collapse` to insert the 'or' symbol.
 - The function then matches the ASV names to the `otu_table()` of the *phyloseq* object to select the desired column(s) that represent the taxa of interest, and then counts the number of rows that have any of the selected taxa with counts greater than 0 to get the number of samples with that taxa present.
 
```{r, warning=F, message=F}
samples_with_taxa <- function(ps_object, taxonomy_level, taxa){
 ASV <- tax_table(ps_object) %>% 
        unclass() %>% 
        as.data.frame() %>% 
        filter_(interp(~y == x, .values=list(y = as.name(taxonomy_level), x = taxa))) %>%
        row.names() %>%
        paste(collapse = " | ")
  
   otu_table(ps_object) %>% 
        as.data.frame() %>% 
        select(matches(ASV)) %>% 
        filter_all(any_vars( . > 0)) %>%  
        nrow()
}

samples_with_taxa(ps4.microbiome, "Genus", "Bifidobacterium")
```

## Beta diversity
 - Use distance and ordination methods to explore the relationship between metadata.
 - We calculate the distances using pruned, transformed and non-agglomerated data.

```{r, warning=F, message=F}
ps2.TSS <- ps2 %>%
        transform_sample_counts(function(x) x / sum(x))
```
 
 - We can then create distance matrices and plots for this data subset using several methods:
 - e.g. bray-curtis or weighted unifrac distances with PCoA, NMDS, etc.
 - Ordinate using PCoA and Weighted-Unifrac/Bray-Curtis.
 - Extract eigenvalues from ordination.
 - Plot ordination using eigenvalues and colour by variable *Date*.

```{r, fig.cap="PCoA plot of Bray-Curtis distances coloured by date.", warning=F, message=F}
ordination_plots <- function(filtered_ps, variable, vis_method, dist_method){
  
# ordinate
ps_ordination <- ordinate(filtered_ps, method = "PCoA", distance = "bray")

# get eignenvalues
evals <- ps_ordination$values$Eigenvalues

# generate plot
plot_ordination(filtered_ps, ps_ordination, color = variable, 
  title = "PCoA (Bray-Curtis)") +
  labs(col = variable) +
  coord_fixed(sqrt(evals[2] / evals[1])) +
  geom_point(size = 2) 

 }

ordination_plots(ps2.Microbiome, "Primary_Group", "PCoA", "bray")
```

 - Export plot.
 
```{r, eval=F}
ggsave("PCoA_Bray.png", 
  plot = (plot_ordination(ps2.TSS, ps_ordination, 
  color = "Type", title = "PCoA (Weighted-Unifrac)") +
  labs(col = "Type") +
  coord_fixed(sqrt(evals[2] / evals[1])) +
  geom_point(size = 2)+
  stat_ellipse(type = "norm", linetype = 2)), dpi = 600, height = 5, width = 5)
```

### Statistical test: PERMANOVA.
 - ps2 transformed.
 - Preforming permutational anova for group-level (*Date* of sample) differences based on dissimilarity.
 - Extract otu table and metadata from phyloseq object.
 - Use `adonis()` from the *vegan* package to perform the PERMANOVA.
 - Homogeneity Condition
  - Significant PERMANOVA means one of three things:
  - there is a difference in the location of the samples (i.e. the average community composition).
  - there is a difference in the dispersion of the samples (i.e. the variability in the community composition).
  - there is a difference in both the location and the dispersion.
  - If you get a significant PERMANOVA you'll want to distinguish between the three options by checking the homogeneity condition using `permdisp()`. If you get a non-significant result the first option above is correct.
  - `betadisper()` gives a measure of the dispersion within groups. Thus, if the PERMANOVA test is significant and the permdisp is not, the significant result in your communities is due to a mean shift in community composition and not from increased variance within groups.
 
```{r, warning=F, message=F}
permanova_func <- function(ps2.TSS){
  
# permanova
ps_otu <- data.frame(otu_table(ps2.TSS))
ps_metadata <- data.frame(sample_data(ps2.TSS))
permanova <- adonis(ps_otu ~Date, data = ps_metadata, method = "bray") 
permanova <- tableGrob(as.data.frame(permanova$aov.tab)) %>% 
  annotate_figure(fig.lab = "PERMANOVA", fig.lab.face = "bold", fig.lab.size = 15)

# homogeneity condition
dist <- vegdist(ps_otu)
homogeneity <- as.data.frame(anova(betadisper(dist, ps_metadata$Date))) %>% 
  tableGrob() %>% 
  annotate_figure(fig.lab = "Homogeneity Condition", fig.lab.face = "bold", fig.lab.size = 15)

# combine ouputs in a grid
grid.arrange(permanova, homogeneity, ncol = 1)

}

permanova_func(ps2.TSS)
```

 - Export results.
 
```{r, eval=F}
tab_df((permanova_func(ps2.TSS)), 
       alternate.rows = TRUE, 
       file = "PERMANOVA.doc")
```

 - Explore the major contributors to the differences.
 **Still trying to workout how to make line 711 more generic. Until then, you need to alter for each variable.**

```{r, warning=F, message=F}
major_contributors <- function(ps2.TSS, variable){
# perform permanova  
ps_otu <- data.frame(otu_table(ps2.TSS))
ps_metadata <- data.frame(sample_data(ps2.TSS))
permanova <- adonis(ps_otu ~Primary_Group, data = ps_metadata, method = "bray") 

# coefficients
coef <- coefficients(permanova)[paste0(variable, "1"),]
top.coef <- coef[rev(order(abs(coef)))[1:20]]

genus_contributors <- tax_table(ps2.TSS) %>% 
    unclass() %>% 
    as.data.frame() %>% 
    select("Genus") %>% 
    rownames_to_column(var = "ASV") %>% 
    right_join((as.data.frame(top.coef) %>%
    rownames_to_column(var = "ASV"))) %>% 
    select(!"ASV") 

return(genus_contributors)
}

major_contributors(ps2.TSS, "Primary_Group")
```

 - Export table.
 
```{r, eval=F}
tab_df(major_contributors(ps2.TSS), alternate.rows = TRUE, 
       title = "Major Contriutors to PERMANOVA differences.", 
       file = "Major_contributors_beta_diversity.doc")
```

## Alpha diversity.
 - Create new subset with ps2 non-transformed data (built in normalisation function for Shannon).
 - Estimate richness and save as object.
 - Remove chao1 standard error column and "X" from row names.
 - Create a new variable column with rownames.
 - Merge alpha diversity estimates (*ps_alpha_div*) with the metadata (*samdf*) by the *Label* column (orignially row names), for downstream analysis.
 
```{r, warning=F, message=F}
calc_alpha_diversity <- function(ps2){
# calculate metrics
ps_alpha_div <- ps2 %>%
                estimate_richness(measures = c("Shannon", "Observed", "Chao1")) %>% 
                select(-se.chao1)

# creat ID column based on rownames
ps_alpha_div <- rownames_to_column(ps_alpha_div, var = "ID") %>% 
                mutate(ID = as.factor(gsub("AM", "", ID)))

# join alpha metrics with metadata by the ID column
Metadata %>%
  filter(Type == "Microbiome") %>% 
  right_join(ps_alpha_div, by = "ID") %>%
  as.data.frame() 
}

ps_metadata <- calc_alpha_diversity(ps2) 
```

 - Create histogram to examine distribution.
 
```{r, warning=F, message=F}
# To determine if diveristy is normally distributed
ggplot(ps_metadata, aes(x = Shannon)) + geom_histogram() + 
       xlab("Alpha Diversity") + ylab("Count")
```

 - Test for normality.
 
```{r, warning=F, message=F}
shapiro.test(ps_metadata$Shannon)
```
 
 ### Statistical test: compare mean/median between groups of **parasite_burden**.
 
```{r, warning=F, message=F}
diversity_analysis <- function(ps_metadata){

Shannon <- compare_means(Shannon ~ parasite_burden, data = ps_metadata, 
                         method = "wilcox.test", p.adjust.method = "fdr")

Observed <- compare_means(Observed ~ parasite_burden, data = ps_metadata, 
                          method = "wilcox.test", p.adjust.method = "fdr")

Chao1 <- compare_means(Chao1 ~ parasite_burden, data = ps_metadata, 
                       method = "wilcox.test", p.adjust.method = "fdr")

bind_rows(Shannon, Observed, Chao1) %>%
  rename(c(".y." = "Diversity Measure"))
}

diversity_analysis(ps_metadata)
```

Shannon diversity over time
```{r}
ps_metadata %>% 
ggplot(aes(x = ddPCR, y = Shannon)) + 
  geom_point() +
  geom_smooth(method = "lm", se = T)
```

 - Export *Diversity_Analysis* results table.
 
```{r, eval=F}
tab_df(diversity_analysis(ps_metadata), alternate.rows = TRUE, 
       title = "Diversity Analysis: Admission Vs Discharge", 
       file = "Alpha_Diversity_Analysis_Type.doc")
```

### Plot alpha diversity.

 - Use `plot_richness()` from *phyloseq*, which estimates alpha diversity metrics using *vegan* and plots them, taking standard *ggplot2* *geoms_* for the plot design.
 - use ps2 non-transformed data for alpha.
 
```{r, warning=F, message=F, fig.cap="Scatterplot of richness and shannon diversity metrics coloured by ddPCR."}
plot_richness(ps2, measures = c("Shannon", "Observed"), 
              color = "ddPCR", title = "") +
    geom_point(size = 3.5, alpha = 0.7) +
    theme(axis.text.x = element_blank(), 
          axis.ticks.x = element_blank(), 
          panel.border = element_rect(colour = "grey", fill = NA, size = 1))
```

 - Export scatterplot.
 
```{r, eval=F}
ggsave("Alpha_Point.png", dpi = 600, height = 5, width = 5)
```

 - Use `plot_richness()` to create boxplots of alpha diversity.
 - To add a layer with p values use `stat_compare_means(comparisons = list(c("Admission", "Discharge")), method = "wilcox.test")`.
 
```{r, warning=F, message=F, fig.cap="Boxplots of richness and shannon diversity metrics coloured by date."}
plot_richness(ps2, measures = c("Shannon", "Observed"), 
              x = "parasite_burden", color = "parasite_burden", title = "") +
              geom_jitter(size = 1, alpha = 0.7) +
              geom_boxplot() +
              theme(panel.border = element_rect(colour = "grey", fill = NA, size = 1), legend.position = "none", 
              axis.text.x = element_blank(), axis.ticks = element_blank()) + 
              stat_compare_means()
```

 - Export boxplot.
 
```{r, eval=F}
ggsave("Alpha_Box.png", dpi = 600, height = 5, width = 5)
```


# DESeq2 Analysis.

## About.

This section is for exploring the impact relationship between the microbiome, parasite concentration and environmental variables.

## Mixed effects modelling with [*DESeq2*](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-014-0550-8) for differential abundance testing.

```{r, warning=F, message=F, results='hide'}
sapply(c("DESeq2", "phyloseq", "dplyr", "ggplot2", "grid", 
         "gridExtra", "ggpubr", "sjPlot", "pheatmap", "tidyverse"), 
          require, character.only = TRUE)
```

### Explore clustering of variables with PCoA and Bray-Curtis.

```{r, fig.cap="PCoA plot of Bray-Curtis distances coloured by date.", warning=F, message=F}
ordination_plots(ps2.Microbiome, "Primary_Group", "PCoA", "bray")
```

#### For multiple plots.

```{r, eval=F}
grid.arrange(ordination_plots(ps2.Microbiome, "Primary_Group", "PCoA", "bray"), 
             ordination_plots(ps2.Microbiome, "Feeding_Type", "PCoA", "bray")
             ,ncol=2)
```

########################################################################################
### Subset data for modelling.

 - Subset to filtered/agglomerated data and scale continuous variables.

#### Testing for multicollinearity.
 - Define the `corvif()`function that takes metadata and creates a linear model to see if any collinearity exists between variables.
 - Then use this function on a defined a vector with all the variables to be included in the model.
 - If GVIF < 3 = no collinearity.
 
```{r, eval=F}
# Get scaled data for colinearity 
cor_met <- sample_data(ps3.Microbiome) %>% unclass %>% as.data.frame()

# Model with ddPCR
corvif(cbind(cor_met$Date, cor_met$ddPCR))

rm(cor_met)
```

## DESeq2
 - Define function for calculating geometric means.
 - Calculate geometric means, and subsetuently estimate size factors.
 - Define function to subset out taxa with small counts and low occurance (count of at least **10** in **60** or more samples).
 
```{r, warning=F, message=F}
calc_geo_means <- function(deseq_object){
# geometric mean
  gm_mean = function(x, na.rm = TRUE){
    exp(sum(log(x[x > 0]), na.rm = na.rm) / length(x))
  }
  geoMeans <- apply(counts(deseq_object), 1, gm_mean)
# size factors
  estimateSizeFactors(deseq_object, geoMeans = geoMeans) 
}

deseq_filter <- function(deseq_object){
  nc <- counts(deseq_object, normalized = TRUE)
  filtered <- rowSums(nc >= 10) >= 60 # filter = abundance of 10 in 60 samples.
  deseq_object[filtered,]
}
```

 - Define a function to extract the results.
 - Extract the results, order by p value, selects significant (<0.05) results, binds this data to the *tax_table* from the *phyloseq* object to get the taxonomic information, and then select and order the desired columns.

Define function for LRT
```{r, warning=F, message=F}
get_deseq_res_lrt <- function(deseq_object){
  res = results(deseq_object)
  res = res[order(res$padj, na.last = NA), ]
  sigtab = res[(res$padj < 0.01), ] 
  sigtab = cbind(as(sigtab, "data.frame"), 
          as(tax_table(ps3.Microbiome)[rownames(sigtab), ], "matrix"))
  sigtab %>%
  arrange(padj) %>%
  select("log2FoldChange", "lfcSE", "padj", "Genus") 
}
```
 
 - Convert from *phyloseq* to *deseq* object.
 - Calculate geometric means and filter to the most abundant and frequent taxa.
 - Use `Deseq()` to perform the normalisation and analysis.
 - Extract the results.
 
### **Analysis for ddPCR and Date**

#### **Univariate**

```{r, warning=F, message=F}
phyloseq_to_deseq2(ps3.Microbiome, ~ ddPCR) %>% 
    calc_geo_means() %>% 
    deseq_filter() %>% 
    DESeq(fitType = "local", test = "LRT", reduced = ~ 1) %>% 
    get_deseq_res_lrt() %>% 
    remove_rownames()
```

```{r, warning=F, message=F}
phyloseq_to_deseq2(ps3.Microbiome, ~ Date) %>% 
    calc_geo_means() %>% 
    deseq_filter() %>% 
    DESeq(fitType = "local", test = "LRT", reduced = ~ 1) %>% 
    get_deseq_res_lrt() %>% 
    remove_rownames()
```

**Its interesting to see the significant overlap in significant DEGs between the date and rain (line 1269), especially when looking at PCoA plots above, which follow very similar patterns.**

#### **Multivariate: Date and ddPCR**

**LRT** for Date
```{r, warning=F, message=F}
phyloseq_to_deseq2(ps3.Microbiome, ~ Date + ddPCR) %>% 
    calc_geo_means() %>% 
    deseq_filter() %>% 
    DESeq(fitType = "local", test = "LRT", reduced = ~ ddPCR) %>% 
    get_deseq_res_lrt() %>% 
    remove_rownames() 
```


**LRT** for ddPCR
```{r, warning=F, message=F, results='hide'}
phyloseq_to_deseq2(ps3.Microbiome, ~ Date + ddPCR) %>% 
    calc_geo_means() %>% 
    deseq_filter() %>% 
    DESeq(fitType = "local", test = "LRT", reduced = ~ Date) %>% 
    get_deseq_res_lrt() %>% 
    remove_rownames()  
```

**For LRT: the paraiste concentration has a significant association with Lewinella when modelled with WITH the date, and Coraliomargarita when on its own. Day appears to have a VERY significant effect - i.e. many taxa.**

**Wald** for ddPCR

**Univariate**

```{r, warning=F, message=F}
get_deseq_res_cont <- function(deseq_object, contrast_variable){
  res = results(deseq_object, name = contrast_variable)
  res = res[order(res$padj, na.last = NA), ]
  sigtab = res[(res$padj < 0.05), ] 
  sigtab = cbind(as(sigtab, "data.frame"), 
          as(tax_table(ps3.Microbiome)[rownames(sigtab), ], "matrix"))
  sigtab %>%
  arrange(padj) %>%
  select("log2FoldChange", "lfcSE", "padj", "Genus") 
}

phyloseq_to_deseq2(ps3.Microbiome, ~ ddPCR) %>% 
    calc_geo_means() %>% 
    deseq_filter() %>% 
    DESeq(fitType = "local", test = "Wald") %>% 
    get_deseq_res_cont("ddPCR") %>% 
    remove_rownames()
```


**Multivariate**
 - should return fewer DEGs, but with majority overlap to the LRT.
```{r, warning=F, message=F}
phyloseq_to_deseq2(ps3.Microbiome, ~ Date + ddPCR) %>% 
    calc_geo_means() %>% 
    deseq_filter() %>% 
    DESeq(fitType = "local", test = "Wald") %>% 
    get_deseq_res_cont("ddPCR") %>% 
    remove_rownames()
```


**For the Wald test: the paraiste concentration has a significant association with Lewinella and Clade_la.**

#### **High VS Low Parasite concentrations**

**Multivariate Wald test for parasite_burden**
 - define a new function for categorical variables, specifically the parasite burden.
```{r, warning=F, message=F, results='hide'}
get_deseq_res_cat <- function(desq_object, contrast_variable, level1, level2){
  res = results(desq_object, contrast = c(contrast_variable, level1, level2))
  res = res[order(res$padj, na.last = NA), ]
  alpha = 0.05
  sigtab = res[(res$padj < alpha), ] 
  sigtab = cbind(as(sigtab, "data.frame"), 
    as(tax_table(ps3.Microbiome)[rownames(sigtab), ], "matrix"))
  sigtab %>%
  arrange(padj) %>%
  select("log2FoldChange", "lfcSE", "padj", "Genus") %>%
  add_column(Variable = paste0(contrast_variable, ":High"))
}

phyloseq_to_deseq2(ps3.Microbiome, ~ Date + parasite_burden) %>% 
    calc_geo_means() %>% 
    deseq_filter() %>% 
    DESeq(fitType = "local", test = "Wald") %>% 
    get_deseq_res_cat("parasite_burden", "High", "Low")
```
**No significant differences between high and low concentrations when modelled with date.**

**Univariate Wald test for parasite_burden**
```{r, warning=F, message=F}
phyloseq_to_deseq2(ps3.Microbiome, ~ parasite_burden) %>% 
    calc_geo_means() %>% 
    deseq_filter() %>% 
    DESeq(fitType = "local", test = "Wald") %>% 
    get_deseq_res_cat("parasite_burden", "High", "Low") %>% 
    remove_rownames()
```

**No significance for the multivariate version of the high vs low parasite concentrations of parasite. Significant results for the univariate comaprison.**

**USE THESE TAXA FOR MIXED MODELLING**


**Try with species**
 - Create a phyloseq object to ps2 (pre-agglomeration), convert to ps2.TSS and run the same analysis as above.
```{r, eval=F}
ps.species <- phyloseq(otu_table(seqtab.microdecon, taxa_are_rows=FALSE), 
               sample_data(Metadata), 
               tax_table(taxa_with_species)) %>% 
               subset_taxa(!is.na(Phylum) & !Phylum %in% c("", "uncharacterized"))

prevalenceThreshold = 0.01 * nsamples(ps.species)
keepTaxa = rownames(prevdf)[(prevdf$Prevalence >= prevalenceThreshold)]
ps.species = prune_taxa(keepTaxa, ps.species)

ps.species <- subset_samples(ps.species, Type == "Microbiome")

get_deseq_res <- function(deseq_object){
  res = results(deseq_object)
  res = res[order(res$padj, na.last = NA), ]
  sigtab = res[(res$padj < 1), ] 
  sigtab = cbind(as(sigtab, "data.frame"), 
          as(tax_table(ps.species)[rownames(sigtab), ], "matrix"))
  sigtab %>%
  arrange(padj) %>%
  select("log2FoldChange", "lfcSE", "padj", "Genus", "Species") 
}


phyloseq_to_deseq2(ps.species, ~ Date + ddPCR) %>% 
    deseq_filter() %>% 
    DESeq(fitType = "local", test = "LRT", reduced = ~ Date) %>% 
    get_deseq_res() %>% 
    remove_rownames()
```

### **Protocol 2: Environmental Variables**

**Univariate**

**LRT**
```{r, message=F, warning=F}
phyloseq_to_deseq2(ps3.Microbiome, ~ RainGauge_mm) %>% 
    calc_geo_means() %>% 
    deseq_filter() %>% 
    DESeq(fitType = "local", test = "LRT", reduced = ~ 1) %>% 
    get_deseq_res_lrt() %>% 
    remove_rownames()
```

**Redefine cont function with a lower p value and no contrast variable to explore univariate effects of env variables**. This lower p value is to tighten up the criteria for inclusion into a multivariant model, which is sensitive to the number of variables.
```{r, message=F, warning=F}
get_deseq_res_uni <- function(deseq_object){
  res = results(deseq_object)
  res = res[order(res$padj, na.last = NA), ]
  sigtab = res[(res$padj < 0.01), ] 
  sigtab = cbind(as(sigtab, "data.frame"), 
          as(tax_table(ps3.Microbiome)[rownames(sigtab), ], "matrix"))
  sigtab %>%
  arrange(padj) %>%
  select("log2FoldChange", "lfcSE", "padj", "Genus") 
}
```

**Wald**
```{r, warning=F, message=F}
phyloseq_to_deseq2(ps3.Microbiome, ~ RainGauge_mm) %>% 
    calc_geo_means() %>% 
    deseq_filter() %>% 
    DESeq(fitType = "local") %>% 
    get_deseq_res_uni() %>% 
    remove_rownames()
```

Variables with p<0.01 and (number of significant taxa).
 - Temperature (10), Rain (15), pH (13), RDO (11), ORP (10), Salinity (8)


**Multivariate**

 - Subset to filtered/agglomerated data and scale continuous variables.
 
```{r, warning=F, message=F}
ps3.Microbiome <- subset_samples(ps3, Type == "Microbiome")

centre_and_scale <- function(data1){
# get numeric variables
data2 <- data1 %>% 
  select_if(is.numeric)
# entering and scaling over variables
data3 <- sapply(data2, function(x) scale(x, center=T, scale = 2*sd(x))) %>% 
  as.data.frame() %>% 
  rownames_to_column("RowID")
# join scaled/centred data to non-numeric data
data1 %>% 
  select_if(negate(is.numeric)) %>%
  rownames_to_column("RowID") %>% 
  left_join(data3, by = "RowID") %>%
  select(-RowID)
}

sample_data(ps3.Microbiome) <- sample_data(ps3.Microbiome) %>% 
  unclass() %>% 
  as.data.frame() %>% 
  centre_and_scale() %>%   
  mutate("Sample" = ID) %>% # need to redo the rownames to save it back into the original ps object
  mutate(Sample = paste0("AM", Sample)) %>% 
  column_to_rownames("Sample") 
```

#### Testing for multicollinearity.
 - Define the `corvif()`function that takes metadata and creates a linear model to see if any collinearity exists between variables.
 - Then use this function on a defined a vector with all the variables to be included in the model.
 - If GVIF < 3 = no collinearity.
 
```{r, eval=F}
# Get scaled data for colinearity 
cor_met <- sample_data(ps3.Microbiome) %>% unclass %>% as.data.frame()

##### Model with ddPCR
corvif(cbind(cor_met$Temperature_C, cor_met$pH, cor_met$RDO_Conc_mgL, cor_met$ORP_mV, cor_met$RainGauge_mm, cor_met$Salinity_PSU, cor_met$ddPCR))

# rain
corvif(cbind(cor_met$ORP_mV, cor_met$RainGauge_mm, cor_met$Salinity_PSU, cor_met$ddPCR))

corvif(cbind(cor_met$RDO_Conc_mgL, cor_met$ORP_mV, cor_met$RainGauge_mm, cor_met$Salinity_PSU, cor_met$ddPCR))

# temp
corvif(cbind(cor_met$Temperature_C, cor_met$pH, cor_met$ORP_mV, cor_met$Salinity_PSU, cor_met$ddPCR))

corvif(cbind(cor_met$Temperature_C, cor_met$RDO_Conc_mgL, cor_met$ORP_mV, cor_met$Salinity_PSU, cor_met$ddPCR))



##### Model With parasite_burden (high vs low)
corvif(cbind(cor_met$Temperature_C, cor_met$pH, cor_met$RDO_Conc_mgL, cor_met$ORP_mV, cor_met$RainGauge_mm, cor_met$Salinity_PSU, cor_met$parasite_burden))

# rain
corvif(cbind(cor_met$RDO_Conc_mgL, cor_met$ORP_mV, cor_met$RainGauge_mm, cor_met$Salinity_PSU, cor_met$parasite_burden))

corvif(cbind(cor_met$ORP_mV, cor_met$RainGauge_mm, cor_met$Salinity_PSU, cor_met$parasite_burden))

# temp
corvif(cbind(cor_met$Temperature_C, cor_met$RDO_Conc_mgL, cor_met$ORP_mV, cor_met$Salinity_PSU, cor_met$parasite_burden))

corvif(cbind(cor_met$Temperature_C, cor_met$pH, cor_met$ORP_mV, cor_met$Salinity_PSU, cor_met$parasite_burden))


rm(cor_met)
```


**NB**
 - CANNOT have temperature and rain in the same model.
 - CANNOT have rain and pH in the same model.
 - *ddPCR* and *parasite_burden* can have the same models formulas, and I beleive that the model with **Rain** would be best based on the results of the **PCoA**. However, they are extremely similar.
 - If the environmental variables are the average of a date, the model(s) would have to be either a combination of the variables or just date and parasite concentration.
 - As the parasite concentration is different between samples, date and parasite concentration variables are still independent, and they are also not collinear. However, there still could be some level of relationship but modelling together should be fine.

**Model Options - based on PCoA, univariate DESeq2 analysis and collinearity tests:**
 - pH/RDO_Conc_mgL, ORP_mV, RainGauge_mm, Salinity_PSU & ddPCR/paraiste_burden.
 - pH/RDO_Conc_mgL, ORP_mV, Temperature_C, Salinity_PSU & ddPCR/paraiste_burden.
 
 
**Giana's Suggestions: "To choose from the water quality parameters, my preference would be to keep first the rain levels, second Temperature, third turbidity, fourth Oxygen and then pH".**

**Final models**
 - RDO_Conc_mgL, ORP_mV, RainGauge_mm, Salinity_PSU & paraiste_burden
 - RDO_Conc_mgL, ORP_mV, RainGauge_mm, Salinity_PSU & paraiste_burden

**I would argue that Rain would be a better option over temperature based on the PCoA.**

Create a stricter p threshold for results functions.
```{r}
# categorical
get_deseq_res_cat <- function(desq_object, contrast_variable, level1, level2){
  res = results(desq_object, contrast = c(contrast_variable, level1, level2))
  res = res[order(res$padj, na.last = NA), ]
  alpha = 0.01
  sigtab = res[(res$padj < alpha), ] 
  sigtab = cbind(as(sigtab, "data.frame"), 
    as(tax_table(ps3.Microbiome)[rownames(sigtab), ], "matrix"))
  sigtab %>%
  arrange(padj) %>%
  select("log2FoldChange", "lfcSE", "padj", "Genus") %>%
  add_column(Variable = paste0(contrast_variable, ":High"))
}

get_deseq_res_cont <- function(deseq_object, contrast_variable){
  res = results(deseq_object, name = contrast_variable)
  res = res[order(res$padj, na.last = NA), ]
  sigtab = res[(res$padj < 0.01), ] 
  sigtab = cbind(as(sigtab, "data.frame"), 
          as(tax_table(ps3.Microbiome)[rownames(sigtab), ], "matrix"))
  sigtab %>%
  arrange(padj) %>%
  select("log2FoldChange", "lfcSE", "padj", "Genus") %>% 
  add_column(Variable = contrast_variable)
}

```
 
**Rain Model with parasite burden**
```{r, message=F, warning=F}
deseq_model <- phyloseq_to_deseq2(ps3.Microbiome, ~ RDO_Conc_mgL + ORP_mV + 
                 RainGauge_mm + Salinity_PSU + parasite_burden) %>% 
               calc_geo_means() %>% 
               deseq_filter() %>% 
               DESeq(fitType = "local", test = "Wald") 

deseq_model <- deseq_model %>% get_deseq_res_cat("parasite_burden",  "High", "Low") %>% 
    remove_rownames() %>% 
    rbind(deseq_model %>% 
            get_deseq_res_cont("RDO_Conc_mgL") %>% 
            remove_rownames()) %>% 
    rbind(deseq_model %>% 
            get_deseq_res_cont("ORP_mV") %>% 
            remove_rownames()) %>% 
    rbind(deseq_model %>% 
            get_deseq_res_cont("RainGauge_mm") %>% 
            remove_rownames()) %>% 
    rbind(deseq_model %>% 
            get_deseq_res_cont("Salinity_PSU") %>% 
            remove_rownames()) 
```

**Rain Model with ddPCR**
```{r, message=F, warning=F}
deseq_model <- phyloseq_to_deseq2(ps3.Microbiome, ~ RDO_Conc_mgL + ORP_mV + 
                  RainGauge_mm + Salinity_PSU + ddPCR) %>% 
               calc_geo_means() %>% 
               deseq_filter() %>% 
               DESeq(fitType = "local", test = "Wald") 

deseq_model <- deseq_model %>% 
            get_deseq_res_cont("ddPCR") %>% 
            remove_rownames() %>% 
    rbind(deseq_model %>% 
            get_deseq_res_cont("RDO_Conc_mgL") %>% 
            remove_rownames()) %>% 
    rbind(deseq_model %>% 
            get_deseq_res_cont("ORP_mV") %>% 
            remove_rownames()) %>% 
    rbind(deseq_model %>% 
            get_deseq_res_cont("RainGauge_mm") %>% 
            remove_rownames()) %>% 
    rbind(deseq_model %>% 
            get_deseq_res_cont("Salinity_PSU") %>% 
            remove_rownames()) 
```

Export
```{r, eval=F}
tab_df(deseq_model, alternate.rows = TRUE, 
       title = "Significantly Differentially Abundant Taxa", 
       file = "DESeq2_Mixed_Model.doc")
```

**Temperature Model**
```{r, eval=F}
deseq_model <- phyloseq_to_deseq2(ps3.Microbiome, ~ RDO_Conc_mgL + ORP_mV + 
                 Temperature_C + Salinity_PSU + parasite_burden) %>% 
               calc_geo_means() %>% 
               deseq_filter() %>% 
               DESeq(fitType = "local", test = "Wald") 

deseq_model %>% get_deseq_res_cat("parasite_burden",  "High", "Low") %>% 
    remove_rownames() %>% 
    rbind(deseq_model %>% 
            get_deseq_res_cont("RDO_Conc_mgL") %>% 
            remove_rownames()) %>% 
    rbind(deseq_model %>% 
            get_deseq_res_cont("ORP_mV") %>% 
            remove_rownames()) %>% 
    rbind(deseq_model %>% 
            get_deseq_res_cont("Temperature_C") %>% 
            remove_rownames()) %>% 
    rbind(deseq_model %>% 
            get_deseq_res_cont("Salinity_PSU") %>% 
            remove_rownames()) %>% 
    rbind(deseq_model %>% 
            get_deseq_res_cont("Salinity_PSU") %>% 
            remove_rownames()) 
```

**The two models are "somewhat" comparable with both each other and the univariate analysis of each variable.**

To make the threshold for signicant results more stringent use either `lfcThreshold = 1` in `results()`function or lower the p value again.
 
 
### DESeq2 Plots
 - Construct histograms to compare pre and post transformation.
 - Call `estimateDispersions()` to calculate abundances with `getVarianceStabilizedData()`.
 - **NB** piped to `calc_geo_means()` to calculate geometric means and estimate size factors, which is needed for the above.
 - **NB.** the samples are in columns in the *deseq* object but in rows for the *phyloseq* object.
```{r, warning=F, message=F, fig.cap="Pre and post transformation of taxonomic counts with DESeq2"}
plot_deseq_transformation <- function(deseq_object){
multi.deseq <- estimateDispersions(deseq_object, fitType = "local")  

abund_sums_trans <- data.frame(sum = colSums(getVarianceStabilizedData(multi.deseq) ), 
                     sample = colnames(getVarianceStabilizedData(multi.deseq) ), 
                     type = "DESeq2")

abund_sums_no_trans <- data.frame(sum = rowSums(otu_table(ps3.Microbiome)), 
                       sample = rownames(otu_table(ps3.Microbiome)), 
                       type = "None")

grid.arrange((ggplot(abund_sums_trans) +
  geom_histogram(aes(x = sum), binwidth = 1) +
  xlab("Abundance within sample") +
  ggtitle("DESeq2 transformation")),
  (ggplot(abund_sums_no_trans) +
  geom_histogram(aes(x = sum), binwidth = 200) +
  xlab("Abundance within sample") +
  ylim(0,4) +
  ggtitle("No transformation")),
  nrow = 2)
}

phyloseq_to_deseq2(ps3.Microbiome, ~ Date + ddPCR) %>% calc_geo_means() %>% plot_deseq_transformation()
```


### Visualisations for *deseq* modelling.

 - Visualising deseq-transformed abundances with heat maps.
 
```{r, warning=F, message=F, eval=F}
phyloseq_to_deseq2(ps3.Microbiome, ~ Date + ddPCR) %>% 
    calc_geo_means() %>% 
    deseq_filter() %>% 
    DESeq(fitType = "local", test = "LRT", reduced = ~ ddPCR) %>%
    varianceStabilizingTransformation() %>%
    assay() %>% 
    cor() %>%
    pheatmap()
```

 - Visualising deseq-transformed abundances with PCA (substitute in any variable).
 
```{r, warning=F, message=F, eval=F}
multi.deseq.clean %>%
  varianceStabilizingTransformation() %>% 
  plotPCA(intgroup = "Mode.of.Delivery") +
   xlim(-20,20)+
   ylim(-20,20)
```


# Mixed effects modelling with glms
**Take the abundances of significant ddPCR values and include in a GLM with environmental variables, to see what environmental variables are having an effect**

```{r, warning=F, message=F, results='hide'}
sapply(c("lme4", "nlme", "dplyr", "plyr", "lmerTest", "aods3", 
         "tidyverse", "ggplot2", "MuMIn", "sjPlot", "gridExtra", 
         "grid", "car", "emmeans", "ggpubr"), 
         require, character.only = TRUE)
```

## Exploration


### Data Alpha Diveristy

See if alpha diveristy could act as a proxy for the microbiome, an alternative to including taxa.

Plot shannon diveristy and the ddPCR to see if there is some relationship.
```{r, warning=F, message=F, fig.cap="Scatterplot with a regression line exploring the relationship between ddPCR and Shannon diversity."}
ps_metadata %>% 
ggplot(aes(x = ddPCR, y = Shannon)) + 
  geom_point() +
  geom_smooth(method = "lm", se = T) +
  scale_x_log10()
```

Run a unviariate model to see if Shannon diversity is statistically associated with cryptocaryon.
```{r}
lmer(ddPCR ~ Shannon + (1|Date), data = ps_metadata) %>% car::Anova() %>% as.data.frame(row.names = NULL)

lm(ddPCR ~ Shannon, data = ps_metadata) %>% car::Anova() %>% as.data.frame(row.names = NULL)
```

**From both the plot and linear model it does not look like shannon diversity and the parasite are related.**

### Explore the relationship between different variables and cryptocaryon using column plots
```{r, warning=F, message=F}
Metadata %>% 
  filter(Type == "Microbiome") %>% 
  arrange(ddPCR) %>% 
  ggplot(aes(x=ID, y=ddPCR, colour=Date)) + 
  geom_col()
```

```{r, warning=F, message=F}
Metadata %>% 
  filter(Type == "Microbiome") %>% 
  arrange(ddPCR) %>% 
  ggplot(aes(x=pH, y=ddPCR, colour=Date)) + 
  geom_col()
```

**Interestingly, it is difficult to see any clear patterns coming through.**

### Explore the relationship using Heatmap of samples (columns) ordered by ddPCR and taxa as rows.
```{r, warning=F, message=F, eval=F}
deseq_filter <- function(deseq_object){
  nc <- counts(deseq_object, normalized = TRUE)
  filtered <- rowSums(nc >= 10) >= 100 # filter = abundance of 10 in 100 samples.
  deseq_object[filtered,]
}

phyloseq_to_deseq2(ps3.Microbiome, ~ parasite_burden) %>% 
    calc_geo_means() %>% 
    deseq_filter() %>% 
    DESeq(fitType = "local") %>%
    varianceStabilizingTransformation() %>%
    assay() %>% 
    as.data.frame() %>% 
    relocate(any_of(
      (Metadata %>%
      rownames_to_column("Label") %>% 
      filter(Type == "Microbiome") %>% 
      arrange(ddPCR))$Label)) %>% # arrange columns by ddPCR
    pheatmap(show_rownames = F, show_colnames = F, cluster_cols = F) # only cluster by rows
```

**Again, it is difficult to see any patterns in the plot. However, from DESeq2 analysis there does appear to be a significant relationship**

**NB** to get ASVs to identify taxa
 - save the previous chunk as map_heat.
 - extract the labels.
 - use these labels to get the taxonomy from your the taxonomy tabel.
```{r, eval=F}
map_heat$tree_row$labels

taxa %>% as.data.frame() %>% rownames_to_column("ASV") %>% filter(ASV == "ASV from map_heat$tree_row$labels") %>% View()
```

 - save as an object (map_heat) and then use `map_heat$tree_row$labels`.
 - then `taxa %>% as.data.frame() %>% rownames_to_column("ASV") %>% filter(ASV == "ASV from map_heat$tree_row$labels") %>% View()`


**Modelling Idea**
Taking everything together, I think it would be best to perform a logisitc regression where the dependent is *parasite_burden*, and the independent variables include both taxonomic abundance of significant taxa (DESeq2) and several of the environmental variables. If this models well then we can try backwards selection to find the least complex adequate model.

### Data with DESeq2 normalised microbial counts
 - taxa are what was found to be significant using `phyloseq_to_deseq2(ps3.Microbiome, ~ parasite_burden)` with a Wald test.
```{r, warning=F, message=F}
glm_data <- subset_samples(ps3, Type == "Microbiome") %>% 
  sample_data() %>% 
  unclass() %>% 
  as.data.frame() %>% 
  mutate(ID = paste0("AM", ID)) %>% 
  left_join(
    (phyloseq_to_deseq2(ps3.Microbiome, ~ parasite_burden) %>% 
    calc_geo_means() %>% 
    counts(normalized = TRUE) %>%  
    as.data.frame() %>% 
    filter(rownames(.) == "TTTCGAATCATTCACAATGGGGGAAACCCTGATGGTGCAACGCCGCGTGGGGGATGAAGGCCTTCGGGTTGTAAACCTCTGTCACCAAGGAGCAACAAGCCGGTTCATAGCCGGCCCTGAGTTAACTTGGAGAGGAAGCAGTGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGAGACTGCAAGCGTTACTCGGATTCACTGGGCGTAAAGGGTGCGTAGGCCGCTAAGCGTGTCGGGTGTGAAATCTCGGGGCTCAACCTCGAAACTGCGCCCGAAACTGTTTAGCTAGAGTGTCGGAGAGGTAAGCGGAATTCCAGGTGTAGCGGTGAAATGCGTAGATATCTGGAGGAACACCAATGGCGAAGGCAGCTTACTGGACGACAACTGACGCTGAGGCACGAAAGCGTGGGTAGCGAAAGGG" | 
             rownames(.) ==  "TGAGGAATATTGGACAATGGACGAAAGTCTGATCCAGCCATGCCGCGTGCAGGATGACGGCCCTATGGGTTGTAAACTGCTTTTATACAGGAAGAAACACTCCCACGTGTGGGGGCTTGACGGTACTGTACGAATAAGGATCGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGAGGATCCAAGCGTTATCCGGAATTATTGGGTTTAAAGGGTCCGCAGGCGGTCTATTAAGTCAGAGGTGAAATCTTGCAGCTCAACTGTAAAATTGCCTTTGATACTGGTAGACTTGAGTCATTGTGAAGTGGTTAGAATGTGTGGTGTAGCGGTGAAATGCATAGATATCACACAGAATACCAATTGCGAAGGCAGATCACTAACAATGTACTGACGCTCATGGACGAAAGCGTGGGGAGCGAACAGG" | 
             rownames(.) == "TGGGGAATATTGCACAATGGGGGAAACCCTGATGCAGCAACGCCGCGTGGAGGATGACACATTTCGGTGCGTAAACTCCTTTTATATAGGAAGATAATGACGGTACTATATGAATAAGCGCCGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGAGGGCGCAAGCGTTACTCGGAATCACTGGGCGTAAAGAGCGTGTAGGCGGGTTAATAAGTTTGAAGTGAAATCCTATGGCTCAACCATAGAACTGCTTTGAAAACTGTTAACCTAGAATATGGGAGAGGTAGATGGAATTTCTGGTGTAGGGGTAAAATCCGTAGAGATCAGAAGGAATACCGATTGCGAAGGCGATCTACTGGAACATTATTGACGCTGAGACGCGAAAGCGTGGGGAGCAAACAGG" | 
             rownames(.) == "TGGGGAATCTTAGACAATGGGGGAAACCCTGATCTAGCCATGCCGCGTGAGTGACGAAGGCCTTAGGGTCGTAAAGCTCTTTCGCTGGGGAAGATAATGACTGTACCCAGTAAAGAAACCCCGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGAGGGGGTTAGCGTTGTTCGGAATTACTGGGCGTAAAGCGCGCGTAGGCGGACTGGAAAGTTGGGGGTGAAATCCCGGGGCTCAACCCCGGAACGGCCTCCAAAACTATCAGTCTAGAGTTCGAGAGAGGTGAGTGGAATTCCGAGTGTAGAGGTGAAATTCGTAGATATTCGGAGGAACACCAGTGGCGAAGGCGGCTCACTGGCTCGATACTGACGCTGAGGTGCGAAAGCGTGGGGAGCAAACAGG" | 
             rownames(.) == "TGAGGAATATTGGACAATGGGCGCAAGCCTGATCCAGCCATGCCGCGTGCAGGAAGAATGCCCTATGGGTTGTAAACTGCTTTTATTTGGGAATAAACCTCCTTACGTGTAGGGAGCTGAATGTACCAAACGAATAAGCACCGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGAGGGTGCAAGCGTTATCCGGAATCATTGGGTTTAAAGGGTCCGCAGGCGGGCCTATAAGTCAGTGGTGAAATCCCATCGCTTAACGATGGAACTGCCATTGATACTGTAGGTCTTGAATTCGGTCGAAGTGGGCGGAATGTGTCATGTAGCGGTGAAATGCATAGATATGACACAGAACACCGATAGCGAAGGCAGCTCACTAGGCCTGGATTGACGCTCAGGGACGAAAGCGTGGGGAGCGAACAGG") %>% 
  base::t() %>% 
  as.data.frame() %>% 
  dplyr::rename("Coraliomargarita" = "TTTCGAATCATTCACAATGGGGGAAACCCTGATGGTGCAACGCCGCGTGGGGGATGAAGGCCTTCGGGTTGTAAACCTCTGTCACCAAGGAGCAACAAGCCGGTTCATAGCCGGCCCTGAGTTAACTTGGAGAGGAAGCAGTGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGAGACTGCAAGCGTTACTCGGATTCACTGGGCGTAAAGGGTGCGTAGGCCGCTAAGCGTGTCGGGTGTGAAATCTCGGGGCTCAACCTCGAAACTGCGCCCGAAACTGTTTAGCTAGAGTGTCGGAGAGGTAAGCGGAATTCCAGGTGTAGCGGTGAAATGCGTAGATATCTGGAGGAACACCAATGGCGAAGGCAGCTTACTGGACGACAACTGACGCTGAGGCACGAAAGCGTGGGTAGCGAAAGGG",  
         "NS4_marine_group" = "TGAGGAATATTGGACAATGGACGAAAGTCTGATCCAGCCATGCCGCGTGCAGGATGACGGCCCTATGGGTTGTAAACTGCTTTTATACAGGAAGAAACACTCCCACGTGTGGGGGCTTGACGGTACTGTACGAATAAGGATCGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGAGGATCCAAGCGTTATCCGGAATTATTGGGTTTAAAGGGTCCGCAGGCGGTCTATTAAGTCAGAGGTGAAATCTTGCAGCTCAACTGTAAAATTGCCTTTGATACTGGTAGACTTGAGTCATTGTGAAGTGGTTAGAATGTGTGGTGTAGCGGTGAAATGCATAGATATCACACAGAATACCAATTGCGAAGGCAGATCACTAACAATGTACTGACGCTCATGGACGAAAGCGTGGGGAGCGAACAGG",
         "Acrobacter" = "TGGGGAATATTGCACAATGGGGGAAACCCTGATGCAGCAACGCCGCGTGGAGGATGACACATTTCGGTGCGTAAACTCCTTTTATATAGGAAGATAATGACGGTACTATATGAATAAGCGCCGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGAGGGCGCAAGCGTTACTCGGAATCACTGGGCGTAAAGAGCGTGTAGGCGGGTTAATAAGTTTGAAGTGAAATCCTATGGCTCAACCATAGAACTGCTTTGAAAACTGTTAACCTAGAATATGGGAGAGGTAGATGGAATTTCTGGTGTAGGGGTAAAATCCGTAGAGATCAGAAGGAATACCGATTGCGAAGGCGATCTACTGGAACATTATTGACGCTGAGACGCGAAAGCGTGGGGAGCAAACAGG", 
         "Marivivens" = "TGGGGAATCTTAGACAATGGGGGAAACCCTGATCTAGCCATGCCGCGTGAGTGACGAAGGCCTTAGGGTCGTAAAGCTCTTTCGCTGGGGAAGATAATGACTGTACCCAGTAAAGAAACCCCGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGAGGGGGTTAGCGTTGTTCGGAATTACTGGGCGTAAAGCGCGCGTAGGCGGACTGGAAAGTTGGGGGTGAAATCCCGGGGCTCAACCCCGGAACGGCCTCCAAAACTATCAGTCTAGAGTTCGAGAGAGGTGAGTGGAATTCCGAGTGTAGAGGTGAAATTCGTAGATATTCGGAGGAACACCAGTGGCGAAGGCGGCTCACTGGCTCGATACTGACGCTGAGGTGCGAAAGCGTGGGGAGCAAACAGG", 
         "Salinirepens" = "TGAGGAATATTGGACAATGGGCGCAAGCCTGATCCAGCCATGCCGCGTGCAGGAAGAATGCCCTATGGGTTGTAAACTGCTTTTATTTGGGAATAAACCTCCTTACGTGTAGGGAGCTGAATGTACCAAACGAATAAGCACCGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGAGGGTGCAAGCGTTATCCGGAATCATTGGGTTTAAAGGGTCCGCAGGCGGGCCTATAAGTCAGTGGTGAAATCCCATCGCTTAACGATGGAACTGCCATTGATACTGTAGGTCTTGAATTCGGTCGAAGTGGGCGGAATGTGTCATGTAGCGGTGAAATGCATAGATATGACACAGAACACCGATAGCGAAGGCAGCTCACTAGGCCTGGATTGACGCTCAGGGACGAAAGCGTGGGGAGCGAACAGG") %>% 
  rownames_to_column(var = "ID")), by = "ID")
```

## Centre/Scale numerical values
```{r}
glm_data <- centre_and_scale(glm_data)
```

Test for collinearity
```{r}
# full 
glm_data %>% 
  select(parasite_burden, Temperature_C, pH, Turbidity_NTU, RDO_Conc_mgL, ORP_mV, RainGauge_mm, Salinity_PSU, NS4_marine_group, Salinirepens, Marivivens, Coraliomargarita, Acrobacter) %>% 
  corvif()

# final model
glm_data %>% 
  select(parasite_burden, Turbidity_NTU, ORP_mV, RainGauge_mm, Salinity_PSU, NS4_marine_group, Coraliomargarita, Acrobacter) %>% 
  corvif()
```

### Fit Model

```{r, warning=F, message=F, results='hide'}
lme4::glmer(parasite_burden ~ Turbidity_NTU + ORP_mV + RainGauge_mm + Salinity_PSU + NS4_marine_group + Coraliomargarita + Acrobacter + (1|Date), data = glm_data, family = "binomial") %>% summary()
```

Try model without taxonomy 

```{r}
lme4::glmer(parasite_burden ~ Turbidity_NTU + ORP_mV + RainGauge_mm + Salinity_PSU + (1|Date), data = glm_data, family = "binomial") %>% summary()
```

**AIC suggests taxonomy model is better.**

#### Use [allFit](https://www.rdocumentation.org/packages/lme4/versions/1.1-26/topics/allFit) to see why we might be getting covergence issues

 - If they all work then any non-convergence warning is a false positive.

```{r}
glmer_refit <- lme4::glmer(parasite_burden ~ Turbidity_NTU + ORP_mV + RainGauge_mm + Salinity_PSU + NS4_marine_group + Coraliomargarita + Acrobacter + (1|Date), data = glm_data, family = "binomial") %>% 
  allFit() %>% 
  summary()

glmer_refit$which.OK # which optimisers work
```

 - Calculate the goodness of fit (how the sample data fits the distribution) and  the Pearsons Chi Square coefficient (how likely observed differences arose by chance).
 - Calculate these again post bakwards selection.
 
```{r, eval=F}
lme4::glmer(parasite_burden ~ Turbidity_NTU + ORP_mV + RainGauge_mm + Salinity_PSU + NS4_marine_group + Coraliomargarita + Acrobacter + (1|Date), data = glm_data, family = "binomial") %>% 
  gof()
```

### Backwards Selection.
 - Define a function that determines what variable is contributing least to the model, as determined by AIC score.
 - Then apply that function to the model, and subsequent models, removing variables from the model that are not contributing (first from the interaction and then from the model entirely).
 
```{r, warning=F, message=F}
dfun <- function(x) {
  x$AIC <- x$AIC-min(x$AIC)
  names(x)[2] <- "dAIC"
  x
}

global <- lme4::glmer(parasite_burden ~ Turbidity_NTU + ORP_mV + RainGauge_mm + Salinity_PSU + NS4_marine_group + Coraliomargarita + Acrobacter + (1|Date), data = glm_data, family = "binomial")

dfun(drop1(global))
```

```{r, warning=F, message=F}
qqnorm(resid(global4)) 
```



**FINISIHED** 

[**Link to github repo.**]()