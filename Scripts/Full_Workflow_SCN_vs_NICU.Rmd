---
title: "Full_Workflow"
author: "Jacob Westaway"
date: "Last updated on `r Sys.Date()`"
output: 
  pdf_document: 
    toc: true
    toc_depth: 2
    number_sections: true
header-includes:
  \usepackage{float}
  \floatplacement{figure}{H}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=T, eval=F)
knitr::opts_knit$set(root.dir = 'C:/Users/Jacob/Desktop/Jacob_Uni/Data/SCN_vs_NICU_probiotic_study')
```

# About.

This document contains the workflow for the manuscript *BLANK_BLANK*, and is based on the workflow from the paper [Characterising the bacterial gut microbiome of probiotic-supplmented very-preterm infants](https://github.com/JacobAFW/NICU_Microbiome_Study/blob/main/Complete_Workflow_NICU_Microbiome.pdf),and includes the bioinformatics pipeline to go from raw reads to interpretable abundances, based largely around this [DADA2](https://pubmed.ncbi.nlm.nih.gov/27508062/) workflow developed by *Callahan, et al.*, with removal of contamination with [MicroDecon](https://onlinelibrary.wiley.com/doi/full/10.1002/edn3.11), and the analysis using a combination of the packages [phyloseq](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0061217), [DESeq2](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-014-0550-8), [lme4](https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf) and more.

# Bioinformatics Pipeline.

## About.

Creating an ASV table from raw reads, using [DADA2](https://pubmed.ncbi.nlm.nih.gov/27508062/).

## Load required packages.

```{r, warning=F, message=F, results='hide'}
sapply(c("dada2", "phyloseq", "DECIPHER", "phangorn", "BiocManager", "BiocStyle", 
        "Biostrings", "ShortRead", "ggplot2", "gridExtra", "tibble", "tidyverse"), 
        require, character.only = TRUE)
```

## Read quality.

### Organise forward and reverse fastq filenames into own lists (check file format).
 - First define the file path to the directory containing the fastq files (we will use this several times).
 
```{r, warning=F, message=F}
path <-"Data/new_data"

fnFs <- sort(list.files(path, pattern = "_R1_001.fastq.gz", full.names = TRUE))

fnRs <- sort(list.files(path, pattern = "_R2_001.fastq.gz", full.names = TRUE))
```

### Extract sample names.

```{r, warning=F, message=F}
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
```

\newpage

### Check quality of Forward and Reverse Reads (used to define truncLen in filtering).

```{r, warning=F, fig.cap="Quality of forward reads.", message=F}
plotQualityProfile(fnFs[1:2])
```

```{r, warning=F, fig.cap="Quality of reverse reads.", message=F}
plotQualityProfile(fnRs[1:2])
```

### Assign names for filtered reads.

```{r, warning=F, message=F}
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))

filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
```

### Filter and trim the reads. 
 - Paremeters based on data and quality plots. 
 - `truncLean` defined by when quality plots begin to drop off, but ensuring it is large enough to maintain read overlap (=>20bp) downstream.
 - `trimLeft` is not needed as primers/barcodes already removed.
 - `maxEE = c(2,2)` is for filtering, where the higher the value the more relaxed filtering,allowing more reads to get through. 
 - Good quality data should allow for more stringent parameters (2 is stringent).
 - The number of reads filtered is checked. If reads are too low, can alter parameters.
 
```{r, warning=F, message=F}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen = c(250,250), 
                     trimLeft = c(16,21), 
                     maxN = 0, 
                     maxEE = c(2,2), 
                     truncQ = 2, 
                     rm.phix = TRUE,
                     compress = TRUE, 
                     multithread = FALSE)# windows can't support multithread
head(out)
```

## Infer sequence variants.

### Calculate Error Rates.
 - Error rates are used for sample ineference downstream.
 
```{r, warning=F, message=F, results='hide'}
errF <- learnErrors(filtFs, multithread = TRUE)

errR <- learnErrors(filtRs, multithread = TRUE)
```

### Plot error rates. 
 - Estimated error rates (black line) should be a good fit to observed rates (points) and error should decrease.
 
```{r, warning=F, fig.cap="Error rates for forward reads", message=F}
plotErrors(errF, nominalQ = TRUE)
```

```{r, warning=F, fig.cap="Error rates for reverse reads.", message=F}
plotErrors(errR, nominalQ = TRUE)
```

### Dereplication.
 - Combine indentical sequences into unique sequence bins.
 - Name the derep-class objects by the sample name.
 
```{r, warning=F, message=F}
derepFs <- derepFastq(filtFs, verbose = TRUE)

derepRs <- derepFastq(filtRs, verbose = TRUE)

names(derepFs) <- sample.names

names(derepRs) <- sample.names
```

### Sequence Inference.

```{r, warning=F, message=F, results='hide'}
dadaFs <- dada(derepFs, err = errF, multithread = F)

dadaRs <- dada(derepRs, err = errR, multithread = F)
```

### Inspect denoised data.

```{r, warning=F, message=F, results='hide'}
dadaFs[[1]]

dadaRs[[1]]
```

### Merge Paired Reads and inspect merged data.
 - Removes paired reads that do not perfectly overlap.
 - Arguments represent infered samples AND denoised reads.
 
```{r, warning=F, message=F, results='hide'}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose = TRUE)
```

## Construct amplicon sequence variance (ASV) table and remove chimeras.

### Construct ASV table.
 - Check dimentions and inspect distribution of sequence lengths.
 
```{r, warning=F, message=F, results='hide'}
seqtab <- makeSequenceTable(mergers)

dim(seqtab)

seqtab %>% 
  getSequences() %>% 
  nchar() %>% 
  table()

# SHOULD GET THE SAME OUTPUT AS: table(nchar(getSequences(seqtab)))
```

### Remove chimeras.

```{r, warning=F, message=F}
seqtab.nochim <- removeBimeraDenovo(seqtab, method = "consensus", 
                                    multithread = TRUE, verbose = TRUE)

rm(seqtab)
```

### Track reads through pipeline.

```{r, warning=F, message=F}
getN <- function(x) sum(getUniques(x))

track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), 
               sapply(mergers, getN), rowSums(seqtab.nochim))

colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")

rownames(track) <- sample.names

head(track)

```

## Contamination removal with *MicroDecon*.

```{r, warning=F, message=F}
library(microDecon)
```
 
### Read in metadata (needed for MicroDecon)

```{r}
Metadata  <- readxl::read_excel("Data/New_metadata.xlsx")
```

### Reformat data for *MicroDecon*.
 - **REFORMAT FUNCTION** for your data.
 - Transpose sequencing table (post chimera removal) and convert to a dataframe.
 - Reorder sequencing table by a prior grouping (days).
 - Move blank sample columns to the start of the sequencing table.
 - Turn row names into their own column as *MicroDecon* requires that the OTUs have a unique ID in column 1.
 
```{r}
wrangle_microdecon <- function(seqtab.nochim){
  
# transpose data
microdecon.df <- t(seqtab.nochim) %>%
  as.data.frame()

microdecon.df <- microdecon.df %>% 
  relocate("JW219B", "JW220") %>% 
  tibble::rownames_to_column(var = "ID") # turn the rownames into the first column
}

microdecon.df <- wrangle_microdecon(seqtab.nochim)
```


### Decontaminate data using `decon()`.
 - `numb.ind` is the number of columns for each priori grouping.
 - `taxa = F` as there is no taxonomy in the dataframe.
 
```{r, warning=F, message=F}
decontaminated <- decon(data = microdecon.df, numb.blanks = 2, 
                  numb.ind = c(21,3), taxa = F)

```

#### Check *MicroDecon* Outputs.

```{r, eval=F, message=F}
decontaminated$decon.table
decontaminated$reads.removed
decontaminated$OTUs.removed
decontaminated$mean.per.group
decontaminated$sum.per.group
```

### Reformat decon.table.
 - Convert column 1 to row names.
 - Remove blank average column (1).
 - Save rownames as seperate vector to be added back, as row names are removed during apply().
 - Convert numeric values to integers (for downstream analysis).
 - Transpose data.
 
```{r, warning=F, message=F}
seqtab.microdecon <- decontaminated$decon.table %>% 
  remove_rownames() %>% 
  column_to_rownames(var = "ID") %>% 
  select(-1) %>% # remove mean blank
  as.matrix() %>% 
  t()
```

## Remove non-amplified samples and rename all.

```{r}
seqtab.microdecon <- seqtab.microdecon %>% 
  as.data.frame() %>% 
  rownames_to_column("ID") %>% 
  filter(ID != c("JW203", "JW211")) %>% 
  mutate(ID = str_remove(ID, "b")) %>% 
  mutate(ID = str_remove(ID, "JW")) %>% 
  column_to_rownames("ID") %>% 
  as.matrix()
```

### Merging multiple sequence runs.
 
```{r, include=F}
# Reading in pilot data for rmd.
seqtab.combined <- read_csv("Data/seqtab_original.csv") %>%
  column_to_rownames("ID") %>% 
  as.matrix() %>% 
  mergeSequenceTables(seqtab.microdecon)
```

## Assign taxonomy.
 - With optional species addition (there is an agglomeration step downstream, so you can add species now for curiosities sake, and remove later for analysis).
 
```{r, warning=F, message=F}
taxa <- assignTaxonomy(seqtab.microdecon, "Data/silva_nr_v132_train_set.fa.gz")

taxa.print <- taxa # Removes sequence rownames for display only
rownames(taxa.print) <- NULL
```

# Species assignment on hpc
```{r}
taxa <- addSpecies(taxa, "Data/silva_species_assignment_v132.fa.gz") 
```

### Calculate percentage of NA taxa
```{r}
sum(is.na(taxa))/prod(dim(taxa)) * 100

apply(taxa, 2, function(col)sum(is.na(col))/length(col)) * 100
```

# Preprocessing: Creating a Phyloseq Object.

## About.
Creating a [phyloseq](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0061217) object to be used for analysis, and create different objects to be used for different types of analysis downstream.

## Load required packages. 

```{r, warning=F, message=F, results='hide'}
sapply(c("caret", "pls", "e1071", "ggplot2", 
    "randomForest", "tidyverse", "ggrepel", "nlme", "devtools", 
    "reshape2", "PMA", "structSSI", "ade4","ggnetwork", 
    "intergraph", "scales", "readxl", "genefilter", "impute", 
    "phyloseq", "phangorn", "dada2", "DECIPHER", "gridExtra", "stringi", "janitor"), 
    require, character.only = TRUE)
```

## Import metadata.

```{r}
Metadata <- readxl::read_excel("Data/New_metadata.xlsx") %>% 
  select(-c(3, 18, 21)) %>% 
  add_column("Primary_Group" = "SCN", "Type" = "Discharge") %>% 
  rbind(
    readxl::read_excel("Data/Old_metadata.xlsx") %>% 
      separate(DOB, into = c("DOB", "Time"), sep = "\\s") %>% 
      mutate(DOB = as.Date(DOB)) %>% 
      select(1, 3:4, 9, 17:18, 20:35)) %>% 
  add_row(URN = "ZymoDNA1", ID = "ZymoDNA1") %>% 
  add_row(URN = "ZymoDNA2", ID = "ZymoDNA2") %>% 
  add_row(URN = "ZymoDNA4", ID = "ZymoDNA3") %>% 
  mutate(Sample_ID = ID) %>% 
  column_to_rownames("Sample_ID") %>% 
  mutate(Mode_of_Delivery = str_replace(Mode_of_Delivery, "Ceaserean", "Cesarean"))
```

## Constuct a phylogenetic tree (for Phyloseq object downstream, required for distance measures).
 - Peform multiple-allignment.
 - `pml` calculates the likelihood of a given tree, and then `optim.pml()` optimizes the tree topology and branch length for the selected model (GTR+G+I max tree).

```{r, warning=F, message=F, results='hide'}
build_tree <- function(ASV_table){
  
seqs <- getSequences(ASV_table)

names(seqs) <- seqs 

alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA, verbose=FALSE)

phangAlign <- phyDat(as(alignment, "matrix"), type = "DNA")

fitGTR <- phangAlign %>%
  dist.ml() %>%
  NJ() %>%
  pml(data = phangAlign) %>%
  update(k = 4, inv = 0.2) %>%
  optim.pml(model = "GTR", optInv = TRUE, optGamma = TRUE, 
  rearrangement = "NNI", control = pml.control(trace = 0))

detach("package:phangorn", unload = TRUE) # conflicts downstream

return(fitGTR)
}

fitGTR <- build_tree(seqtab.combined)
```

## Constrcut the Phyloseq object.
 - Includes: metadata, ASV table, taxonomy table and phylogenetic tree.
 
```{r, warning=F, message=F, results='hide'}
ps <- phyloseq(otu_table(seqtab.combined, taxa_are_rows=FALSE), 
               sample_data(Metadata), 
               tax_table(taxa))
```

## Wrangling the metadata.
 - And do some additional wrangling.
 - Convert chraracters to factors.

**Change `ID`.**
```{r, warning=F, message=F, results='hide'}
sample_data(ps) <- sample_data(ps) %>%
  unclass() %>%
  as.data.frame() %>%
  mutate_if(is.character, as.factor) %>%
  mutate("Sample" = ID) %>% # need to redo the rownames to save it back into the original ps object
  column_to_rownames("Sample") 
```

### Subset phyloseq object for data to be analyzed.

**Change `Type` and `Discharge`.**
```{r, warning=F, message=F, results='hide'}
ps <- subset_samples(ps, Type == "Discharge")
```

## Filtering and normalisation.

### Taxonomy filtering.
 - Can check the number of phyla before and after transformation with `table(tax_table(ps)[, "Phylum"], exclude = NULL)`.
 - Remove features with ambiguous and NA phylum annotation.

```{r, warning=F, message=F, results='hide'}
ps1 <- subset_taxa(ps, !is.na(Phylum) & !Phylum %in% c("", "uncharacterized"))
```

#### Check percentages of NA values left.

```{r}
sum(is.na(tax_table(ps1)))/prod(dim(tax_table(ps1))) * 100

apply(tax_table(ps1), 2, function(col)sum(is.na(col))/length(col)) * 100
```

### Prevelance filtering.
 - Using an unsupervised method (relying on the data in this experiment) explore the prevelance of features in the dataset.
 - Calculate the prevalence of each feature and store as a dataframe.
 - Add taxonomy and total read counts.
 
```{r, warning=F, message=F, results='hide'}
prevdf = apply(X = otu_table(ps1),
               MARGIN = ifelse(taxa_are_rows(ps1), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})

prevdf = data.frame(Prevalence = prevdf,
                    TotalAbundance = taxa_sums(ps1),
                    tax_table(ps1))
```

 - Plot the relationship between prevelance and total read count for each feature. This provides information on outliers and ranges of features.
 
```{r, warning=F, message=F, fig.cap="Scatterplot exploring the relationship between prevelance and abundance of phyla."}
prevdf %>%
  subset(Phylum %in% get_taxa_unique(ps1, "Phylum")) %>%
  ggplot(aes(TotalAbundance, Prevalence / nsamples(ps1),color=Phylum)) +
  geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 1) +  
  geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +  
  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position="none")
```

 - Define prevalence threshold based on the plot (~1% is standard) and apply to ps object (if prevelance is too low don't designate a threshold).
 
```{r, warning=F, message=F, results='hide'}
prevalenceThreshold = 0.01 * nsamples(ps1)

keepTaxa = rownames(prevdf)[(prevdf$Prevalence >= prevalenceThreshold)]

ps2 = prune_taxa(keepTaxa, ps1)
```

 - Explore the relationship on the filtered data set.
```{r, warning=F, message=F, fig.cap="Scatterplot exploring the relationship between prevelance and abundance of phyla on data passed through a prevalence threshold."}
prevdf %>%
  subset(Phylum %in% get_taxa_unique(ps2, "Phylum")) %>%
  ggplot(aes(TotalAbundance, Prevalence / nsamples(ps2),color=Phylum)) +
  geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 1) +  
  geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +  
  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position="none")
```

### Aggolmerate taxa.
 - Combine features that descend from the same genus as most species have not been identified due to the poor taxonomic depth in 16S, a result of the length of the fragment amplified from the 16SrRNA gene.  
 - Can check how many genera would be present after filtering by running `length(get_taxa_unique(ps2, taxonomic.rank = "Genus"))`, and `ntaxa(ps3)` will give the number of post agglomeration taxa.
 
```{r, warning=F, message=F, results='hide'}
ps3 = tax_glom(ps2, "Genus", NArm = TRUE)
```

 - Create tree plots to observe pre and post agglomeration.
 
```{r, warning=F, message=F, fig.cap="Tree plots exploring the agglomeration of taxa at the genus level."}
grid.arrange(nrow = 1, 
    (plot_tree(ps2, method = "treeonly",
      ladderize = "left", title = "Before Agglomeration") +
      theme(plot.title = element_text(size = 15))), 
    (plot_tree(ps3, method = "treeonly",
      ladderize = "left", title = "Post Genus Agglomeration") +
      theme(plot.title = element_text(size = 15))))
```

### Normalisation.
 - Plot a refraction curve to see if total sum scaling will surfice.
 - Define colours and lines.
 - Step = step size for sample sizes in rarefaction curve.
 
```{r, warning=F, message=F}
vegan::rarecurve(t(otu_table(ps3)), step = 20, label = FALSE, main = "Rarefaction Curve", 
        col = c("black", "darkred", "forestgreen", "orange", "blue", "yellow", "hotpink"))
```

 - Perform total sum scaling on agglomerated dataset.
 
```{r, warning=F, message=F}
ps4 <- transform_sample_counts(ps3, function(x) x / sum(x))
```

 - Explore normalisation with violin plots.
 - Compares differences in scale and distribution of the abundance values before and after transformation.
 - Using arbitrary subset, based on Phylum = Firmicutes, for plotting (ie. can explore any taxa to observe transformation).

**Change `Firmicutes`.**
```{r, warning=F, message=F, fig.cap="Violin plots exploring of distribution of abundance in Firmicutes before and after normalisation of data."}
plot_abundance = function(physeq, Title = "Abundance", Facet = "Order", Color = "Phylum", variable = "Type"){
    subset_taxa(physeq, Phylum %in% c("Firmicutes")) %>%
    psmelt() %>%
    subset(Abundance > 0) %>%
    ggplot(mapping = aes_string(x = variable, y = "Abundance", color = Color, fill = Color)) +
      geom_violin(fill = NA) +
      geom_point(size = 1, alpha = 0.3, position = position_jitter(width = 0.3)) +
      facet_wrap(facets = Facet) + 
      scale_y_log10()+
      theme(legend.position="none") +
      labs(title = Title)
}

grid.arrange(nrow = 2, (plot_abundance(ps3, Title = "Abundance", Color = "Type", variable = "Type")),
             plot_abundance(ps4, Title = "Relative Abundance", Color = "Type", variable = "Type"))
```

 - Explore normalisation with tree plots.

**Change `Type`.**
```{r, warning=F, message=F, fig.cap="Tree plot exploring the normalised distribution of taxa between admission and discharge samples."}
plot_tree(ps4.NICU_no_na, size = "Abundance", color = "Type", 
    justify = "yes please", ladderize = "left") +
    labs(title = "Phylogenetic Tree and Relative Abundance") +
    scale_size_continuous(range = c(.5, 3))
```

# Data Exploration and Univariate Analysis.

## About.
This section again uses the [phyloseq](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0061217) package (along with several others) to explore the data using bar, violin and ordination plot. This then leads into a collection of univariate analyses, including; alpha and beta diversity, and also taxonomic differential abundance.

## Load required packages. 

```{r, warning=F, message=F, results='hide'}
sapply(c("BiocManager", "ggplot2", "ggforce", "vegan", "knitr", "dplyr", 
         "phyloseq", "phyloseqGraphTest", "igraph", "ggnetwork", "nlme", 
         "reshape2", "tidyverse", "plyr", "DESeq2", "sjPlot", "ggpubr", 
         "gridExtra", "grid", "gtable", "lazyeval"), require, character.only = TRUE)
```

## Taxanomic distribution.

### Bar charts
 - Use `plot_bar_auto()` function wrapped around phyloseq's `plot_bar()` to explore the distribution of taxa at the genus and phylum levels.
 - Subset transformed data (relative abundance) to only the top20 taxa.
 
**Change `Primary_Group`.**
```{r, warning=F, message=F, fig.cap="Bar plots of the taxonomic distribution (relative abundance) at phylum and genus levels.", results='hide'}
top20 <- names(sort(taxa_sums(ps4), decreasing=TRUE))[1:20]
ps.top20 <- prune_taxa(top20, ps4)

plot_bar_auto <- function(ps, taxonomy){
plot_bar(ps, fill = taxonomy) + 
    facet_wrap(~Primary_Group, scales = "free_x") + 
    labs(title = paste0("Level:", taxonomy), y = "Abundance") + 
    theme(legend.position = "bottom", legend.title = element_blank(), 
    axis.title.x = element_blank(), axis.text.x = element_blank(), 
    axis.ticks = element_blank())
}

plot_bar_auto(ps.top20, "Phylum")
```

### Calculate the number samples containing a given taxa by creating a `samples_with_taxa()` function.

 - Define a function takes the phyloseq object, taxonomy level and taxanomic name (with the later two as strings). 
 - It then gets the ASV name from the *phyloseq* `tax_table()` by filtering with *dply* and [*lazyeval*](https://cran.r-project.org/web/packages/lazyeval/index.html). ( *lazyeval* is needed because of two concepts;[non-standard evaluation](http://adv-r.had.co.nz/Computing-on-the-language.html) and [lazy evaluation](http://adv-r.had.co.nz/Functions.html#function-arguments).
 - `paste()` is then used to concatenate the ASVs and `collapse` to insert the 'or' symbol.
 - The function then matches the ASV names to the `otu_table()` of the *phyloseq* object to select the desired column(s) that represent the taxa of interest, and then counts the number of rows that have any of the selected taxa with counts greater than 0 to get the number of samples with that taxa present.
 
```{r, warning=F, message=F}
samples_with_taxa <- function(ps_object, taxonomy_level, taxa){
 ASV <- tax_table(ps_object) %>% 
        unclass() %>% 
        as.data.frame() %>% 
        filter_(interp(~y == x, .values=list(y = as.name(taxonomy_level), x = taxa))) %>%
        row.names() %>%
        paste(collapse = " | ")
  
   otu_table(ps_object) %>% 
        as.data.frame() %>% 
        select(matches(ASV)) %>% 
        filter_all(any_vars( . > 0)) %>%  
        nrow()
}

samples_with_taxa(ps4.microbiome, "Genus", "Bifidobacterium")
```

## Beta diversity
 - Use distance and ordination methods to explore the relationship between metadata.
 - We calculate the distances using pruned, transformed (TSS) and non-agglomerated data.

```{r, warning=F, message=F}
ps2.TSS <- ps2 %>%
        transform_sample_counts(function(x) x / sum(x))
```
 
 - We can then create distance matrices and plots for this data subset using several methods:
 - e.g. bray-curtis or weighted unifrac distances with PCoA, NMDS, etc.
 - Define a function that ordindates the previously transformed data, extarcts the eigenvalues, and creates a dissimilarity plot.
 - Extract eigenvalues from ordination.


```{r, fig.cap="PCoA plot of Bray-Curtis distances coloured by date.", warning=F, message=F}
ordination_plots <- function(filtered_ps, variable, vis_method, dist_method){
# ordinate
ps_ordination <- ordinate(filtered_ps, method = vis_method, distance = dist_method)
# get eignenvalues
evals <- ps_ordination$values$Eigenvalues
# generate plot
plot_ordination(filtered_ps, ps_ordination, color = variable, 
  title = "PCoA (Bray-Curtis)") +
  labs(col = variable) +
  coord_fixed(sqrt(evals[2] / evals[1])) +
  geom_point(size = 2) 
 }

ordination_plots(ps2, "Primary_Group", "PCoA", "bray")
```

 - Export plot.
 
```{r, eval=F}
ggsave("PCoA_Bray.png", 
  plot = (plot_ordination(ps2.TSS, ps_ordination, 
  color = "Type", title = "PCoA (Weighted-Unifrac)") +
  labs(col = "Type") +
  coord_fixed(sqrt(evals[2] / evals[1])) +
  geom_point(size = 2)+
  stat_ellipse(type = "norm", linetype = 2)), dpi = 600, height = 5, width = 5)
```

### Statistical test: PERMANOVA.
 - ps2 transformed.
 - Preforming permutational anova for group-level differences based on dissimilarity.
 - Extract otu table and metadata from phyloseq object.
 - Use `adonis()` from the *vegan* package to perform the PERMANOVA.
 - Homogeneity Condition
  - Significant PERMANOVA means one of three things:
  - there is a difference in the location of the samples (i.e. the average community composition).
  - there is a difference in the dispersion of the samples (i.e. the variability in the community composition).
  - there is a difference in both the location and the dispersion.
  - If you get a significant PERMANOVA you'll want to distinguish between the three options by checking the homogeneity condition using `permdisp()`. If you get a non-significant result the first option above is correct.
  - `betadisper()` gives a measure of the dispersion within groups. Thus, if the PERMANOVA test is significant and the permdisp is not, the significant result in your communities is due to a mean shift in community composition and not from increased variance within groups.
  
**Change `Primary_Group`.**
```{r, warning=F, message=F}
permanova_func <- function(ps2.TSS){
  
# permanova
ps_otu <- data.frame(otu_table(ps2.TSS))
ps_metadata <- data.frame(sample_data(ps2.TSS))
permanova <- adonis(ps_otu ~Primary_Group, data = ps_metadata, method = "bray") 
permanova <- tableGrob(as.data.frame(permanova$aov.tab)) %>% 
  annotate_figure(fig.lab = "PERMANOVA", fig.lab.face = "bold", fig.lab.size = 15)

# homogeneity condition
dist <- vegdist(ps_otu)
homogeneity <- as.data.frame(anova(betadisper(dist, ps_metadata$Primary_Group))) %>% 
  tableGrob() %>% 
  annotate_figure(fig.lab = "Homogeneity Condition", fig.lab.face = "bold", fig.lab.size = 15)

# combine ouputs in a grid
grid.arrange(permanova, homogeneity, ncol = 1)

}

permanova_func(ps2.TSS)
```

 - Export results.
 
```{r, eval=F}
tab_df((permanova_func(ps2.TSS)), 
       alternate.rows = TRUE, 
       file = "PERMANOVA.doc")
```

 - Explore the major contributors to the differences.

**Change `Primary_Group`.**
```{r, warning=F, message=F}
major_contributors <- function(ps2.TSS, variable){
# perform permanova  
ps_otu <- data.frame(otu_table(ps2.TSS))
ps_metadata <- data.frame(sample_data(ps2.TSS))
permanova <- adonis(ps_otu ~Primary_Group, data = ps_metadata, method = "bray") 

# coefficients
coef <- coefficients(permanova)[paste0(variable, "1"),]
top.coef <- coef[rev(order(abs(coef)))[1:20]]

genus_contributors <- tax_table(ps2.TSS) %>% 
    unclass() %>% 
    as.data.frame() %>% 
    select("Genus") %>% 
    rownames_to_column(var = "ASV") %>% 
    right_join((as.data.frame(top.coef) %>%
    rownames_to_column(var = "ASV"))) %>% 
    select(!"ASV") 

return(genus_contributors)
}

major_contributors(ps2.TSS, "Primary_Group")
```

 - Export table.
 
```{r, eval=F}
tab_df(major_contributors(ps2.TSS), alternate.rows = TRUE, 
       title = "Major Contriutors to PERMANOVA differences.", 
       file = "Major_contributors_beta_diversity.doc")
```

## Alpha diversity.
 - Define a function that calculates Shannon Index, Obsverved (richness) & Chao1 diversity, and binds it to our original metadata dataframe, which can then be used for analysis.

**Change `ID`.**
```{r, warning=F, message=F}
calc_alpha_diversity <- function(ps2){
# calculate metrics
ps_alpha_div <- ps2 %>%
                estimate_richness(measures = c("Shannon", "Observed", "Chao1")) %>% 
                select(-se.chao1)

# creat ID column based on rownames
ps_alpha_div <- rownames_to_column(ps_alpha_div, var = "ID") %>% 
                mutate(ID = as.factor(gsub("AM", "", ID)))

# join alpha metrics with metadata by the ID column
Metadata %>%
  filter(Type == "Microbiome") %>% 
  right_join(ps_alpha_div, by = "ID") %>%
  as.data.frame() 
}

ps_metadata <- calc_alpha_diversity(ps2) 
```

 - Create histogram to examine distribution.
 
```{r, warning=F, message=F}
# To determine if diveristy is normally distributed
ggplot(ps_metadata, aes(x = Shannon)) + geom_histogram() + 
       xlab("Alpha Diversity") + ylab("Count")
```

 - Test for normality.
 
```{r, warning=F, message=F}
shapiro.test(ps_metadata$Shannon)
```
 
### Statistical test: compare mean/median between groups.
- define a function that performs a Wilcoxin test on the three diversity metrics and binds them (Shannon Index, Richness & Chao1).

**Change `Primary_Group`.**
```{r, warning=F, message=F}
diversity_analysis <- function(ps_metadata){

Shannon <- compare_means(Shannon ~ Primary_Group, data = ps_metadata, 
                         method = "wilcox.test", p.adjust.method = "fdr")

Observed <- compare_means(Observed ~ Primary_Group, data = ps_metadata, 
                          method = "wilcox.test", p.adjust.method = "fdr")

Chao1 <- compare_means(Chao1 ~ Primary_Group, data = ps_metadata, 
                       method = "wilcox.test", p.adjust.method = "fdr")

bind_rows(Shannon, Observed, Chao1) %>%
  rename(c(".y." = "Diversity Measure"))
}

diversity_analysis(ps_metadata)
```

 - Export *Diversity_Analysis* results table.
 
```{r, eval=F}
tab_df(diversity_analysis(ps_metadata), alternate.rows = TRUE, 
       title = "Diversity Analysis: Admission Vs Discharge", 
       file = "Alpha_Diversity_Analysis_Type.doc")
```

### Plot alpha diversity.

 - Use `plot_richness()` from *phyloseq*, which estimates alpha diversity metrics using *vegan* and plots them, taking standard *ggplot2* *geoms_* for the plot design.
 - use ps2 non-transformed data for alpha.
 
```{r, warning=F, message=F, fig.cap="Scatterplot of richness and shannon diversity metrics coloured by ddPCR."}
plot_richness(ps2, measures = c("Shannon", "Observed"), 
              color = "ddPCR", title = "") +
    geom_point(size = 3.5, alpha = 0.7) +
    theme(axis.text.x = element_blank(), 
          axis.ticks.x = element_blank(), 
          panel.border = element_rect(colour = "grey", fill = NA, size = 1))
```

 - Export scatterplot.
 
```{r, eval=F}
ggsave("Alpha_Point.png", dpi = 600, height = 5, width = 5)
```

 - Use `plot_richness()` to create boxplots of alpha diversity.
 - To add a layer with p values use `stat_compare_means(comparisons = list(c("Admission", "Discharge")), method = "wilcox.test")`.

**Change `Primary_Group`.**
```{r, warning=F, message=F, fig.cap="Boxplots of richness and shannon diversity metrics coloured by date."}
plot_richness(ps2, measures = c("Shannon", "Observed"), 
              x = "Primary_Group", color = "Primary_Group", title = "") +
              geom_jitter(size = 1, alpha = 0.7) +
              geom_boxplot() +
              theme(panel.border = element_rect(colour = "grey", fill = NA, size = 1), legend.position = "none", 
              axis.text.x = element_blank(), axis.ticks = element_blank())
```

 - Export boxplot.
 
```{r, eval=F}
ggsave("Alpha_Box.png", dpi = 600, height = 5, width = 5)
```

 - shannon diversity for continuous variable.

**Change `Gestational_Age_at_Birth`.**
```{r}
ps_metadata %>% 
ggplot(aes(x = Gestational_Age_at_Birth, y = Shannon)) + 
  geom_point() +
  geom_smooth(method = "lm", se = T)
```

# Differential abundance analysis with [*DESeq2*](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-014-0550-8).

 - Define function for calculating geometric means and estimating size factors.
 - Define function to filter out taxa with small counts and low occurance. *count* and *samples* arguments need to be applied as numerical values.
 
```{r, warning=F, message=F}
calc_geo_means <- function(deseq_object){
# geometric mean
  gm_mean = function(x, na.rm = TRUE){
    exp(sum(log(x[x > 0]), na.rm = na.rm) / length(x))
  }
  geoMeans <- apply(counts(deseq_object), 1, gm_mean)
# size factors
  estimateSizeFactors(deseq_object, geoMeans = geoMeans) 
}

deseq_filter <- function(deseq_object, count, samples){ 
  nc <- counts(deseq_object, normalized = TRUE)
  filtered <- rowSums(nc >= count) >= samples # filter = abundance of 10 in 60 samples.
  deseq_object[filtered,]
}
```

 - Define a function to extract the results.
 - Extract the results, order by p value, selects significant (<0.05) results, binds this data to the *tax_table* from the *phyloseq* object to get the taxonomic information, and then select and order the desired columns.

```{r, warning=F, message=F}
# function for liklihood ratio test
get_deseq_res_lrt <- function(deseq_object){
  res = results(deseq_object)
  res = res[order(res$padj, na.last = NA), ]
  sigtab = res[(res$padj < 0.05), ] 
  sigtab = cbind(as(sigtab, "data.frame"), 
          as(tax_table(ps3)[rownames(sigtab), ], "matrix"))
  sigtab %>%
  arrange(padj) %>%
  select("log2FoldChange", "lfcSE", "padj", "Genus") 
}

# function for Walds test and continuous variables
get_deseq_res_cont <- function(deseq_object, contrast_variable){
  res = results(deseq_object, name = contrast_variable)
  res = res[order(res$padj, na.last = NA), ]
  sigtab = res[(res$padj < 0.05), ] 
  sigtab = cbind(as(sigtab, "data.frame"), 
          as(tax_table(ps3)[rownames(sigtab), ], "matrix"))
  sigtab %>%
  arrange(padj) %>%
  select("log2FoldChange", "lfcSE", "padj", "Genus") 
}

# function for Walds test and categorical variables
get_deseq_res_cat <- function(desq_object, contrast_variable, level1, level2){
  res = results(desq_object, contrast = c(contrast_variable, level1, level2))
  res = res[order(res$padj, na.last = NA), ]
  alpha = 0.05
  sigtab = res[(res$padj < alpha), ] 
  sigtab = cbind(as(sigtab, "data.frame"), 
    as(tax_table(ps3)[rownames(sigtab), ], "matrix"))
  sigtab %>%
  arrange(padj) %>%
  select("log2FoldChange", "lfcSE", "padj", "Genus") %>%
  add_column(Variable = paste0(contrast_variable, level1)) # label the base level
}
```
 
 - Convert from *phyloseq* to *deseq* object.
 - Calculate geometric means and filter to the most abundant and frequent taxa.
 - Use `Deseq()` to perform the normalisation and analysis.
 - Extract the results.

**Change `Primary_Group`.**
```{r, warning=F, message=F}
# LRT
phyloseq_to_deseq2(ps3, ~ Primary_Group) %>% 
    calc_geo_means() %>% 
    deseq_filter(10,10) %>% 
    DESeq(fitType = "local", test = "LRT", reduced = ~ 1) %>% 
    get_deseq_res_lrt() %>% 
    remove_rownames()
```

**Change `Primary_Group`.**
```{r, warning=F, message=F}
# Wald
phyloseq_to_deseq2(ps3, ~ Primary_Group) %>% 
    calc_geo_means() %>% 
    deseq_filter(10,10) %>% 
    DESeq(fitType = "local", test = "Wald") %>% 
    get_deseq_res_cat("Primary_Group", "NICU", "SCN") %>%
    remove_rownames()
```


# Multivariant Analysis

## Mixed effects modelling with [*DESeq2*](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-014-0550-8) for differential abundance testing.

```{r, warning=F, message=F, results='hide'}
sapply(c("DESeq2", "phyloseq", "dplyr", "ggplot2", "grid", 
         "gridExtra", "ggpubr", "sjPlot", "pheatmap", "tidyverse"), 
          require, character.only = TRUE)
```

### Explore clustering of variables with PCoA and Bray-Curtis.

```{r, fig.cap="PCoA plot of Bray-Curtis distances coloured by probiotic group.", warning=F, message=F}
ordination_plots(ps2, "Primary_Group", "PCoA", "bray")
```

#### For multiple plots.

```{r, eval=F}
grid.arrange(ordination_plots(ps2, "Primary_Group", "PCoA", "bray"), 
             ordination_plots(ps2, "Feeding_Type", "PCoA", "bray"), 
             ncol=2)
```

### Centre and scale continuous variables.

**Change `ID`.**
```{r, warning=F, message=F}
centre_and_scale <- function(data){
# get numeric variables
data2 <- data %>% 
  select_if(is.numeric)
# entering and scaling over variables
data3 <- sapply(data2, function(x) scale(x, center=T, scale = 2*sd(x))) %>% 
  as.data.frame() %>% 
  rownames_to_column("RowID")
# join scaled/centred data to non-numeric data
data %>% 
  select_if(negate(is.numeric)) %>%
  rownames_to_column("RowID") %>% 
  left_join(data3, by = "RowID") %>%
  select(-RowID)
}

sample_data(ps3) <- sample_data(ps3) %>% 
  unclass() %>% 
  as.data.frame() %>% 
  centre_and_scale() %>%   
  mutate("Sample" = ID) %>% # need to redo the rownames to save it back into the original ps object
  column_to_rownames("Sample") 
```

### Test for multicollinearity.
 - Define the `corvif()`function that takes metadata and creates a linear model to see if any collinearity exists between variables.
 - Then use this function on a defined a vector with all the variables to be included in the model.
 - If GVIF < 3 = no collinearity.

```{r}
# myvif
myvif <- function(mod) {
  v <- vcov(mod)
  assign <- attributes(model.matrix(mod))$assign
  if (names(coefficients(mod)[1]) == "(Intercept)") {
    v <- v[-1, -1]
    assign <- assign[-1]
  } else warning("No intercept: vifs may not be sensible.")
  terms <- labels(terms(mod))
  n.terms <- length(terms)
  if (n.terms < 2) stop("The model contains fewer than 2 terms")
  if (length(assign) > dim(v)[1] ) {
    diag(tmp_cor)<-0
    if (any(tmp_cor==1.0)){
      return("Sample size is too small, 100% collinearity is present")
    } else {
      return("Sample size is too small")
    }
  }
  R <- cov2cor(v)
  detR <- det(R)
  result <- matrix(0, n.terms, 3)
  rownames(result) <- terms
  colnames(result) <- c("GVIF", "Df", "GVIF^(1/2Df)")
  for (term in 1:n.terms) {
    subs <- which(assign == term)
    result[term, 1] <- det(as.matrix(R[subs, subs])) * det(as.matrix(R[-subs, -subs])) / detR
    result[term, 2] <- length(subs)
  }
  if (all(result[, 2] == 1)) {
    result <- data.frame(GVIF=result[, 1])
  } else {
    result[, 3] <- result[, 1]^(1/(2 * result[, 2]))
  }
  invisible(result)
}

# corvif
corvif <- function(data) {
  data <- as.data.frame(data)

  form    <- formula(paste("fooy ~ ",paste(strsplit(names(data)," "),collapse = " + ")))
  data  <- data.frame(fooy = 1 + rnorm(nrow(data)) ,data)
  lm_mod  <- lm(form,data) # runs linear model with above formula and metadata
  
  cat("\n\nVariance inflation factors\n\n")
  print(myvif(lm_mod))
}
```

```{r, eval=F}
sample_data(ps3) %>% 
  unclass %>% 
  as.data.frame() %>% 
  select(Feeding_Type, NEC, Sepsis, Died, Mode_of_Delivery, Antenatal_Antibiotics, Neonatal_Antibiotics, Chorioamnionitis, Antenatal_Infections, Prolonged_Membrane_Rupture, Diabetes, Preeclampsia, ROP, Birth_Weight, Nursery_Discharge_Weight, Date_Collected, Gestational_Age_at_Birth, Primary_Group, Type) %>% 
  corvif()
```

## DESeq2

 - Convert from *phyloseq* to *deseq* object.
 - Use prevviously defined functions to calculate geometric means and filter to the most abundant and frequent taxa.
 - Use `Deseq()` to perform the normalisation and analysis.
 - Extract the results using appropriate previosuly defined function.

### LRT

**Change `Primary_Group` & `Feeding_Type`.**
```{r, warning=F, message=F}
phyloseq_to_deseq2(ps3, ~ Primary_Group + Feeding_Type) %>% 
    calc_geo_means() %>% 
    deseq_filter() %>% 
    DESeq(fitType = "local", test = "LRT", reduced = ~ Primary_Group) %>% 
    get_deseq_res_lrt() %>% 
    remove_rownames() 
```

### Wald

**Change variables and arguments.**
```{r, warning=F, message=F}
deseq_model <- phyloseq_to_deseq2(ps3, ~ Primary_Group + Feeding_Type + NEC) %>% 
    calc_geo_means() %>% 
    deseq_filter() %>% 
    DESeq(fitType = "local", test = "Wald")

# rbind the results outputs to create one large output
deseq_model <- deseq_model %>% 
  get_deseq_res_cat("Primary_Group", "Admission", "Discharge") %>% 
  remove_rownames() %>% 
  rbind(get_deseq_res_cat("Feeding_Type", "Breastmilk", "Formula") %>% 
  remove_rownames()) %>% 
  rbind(get_deseq_res_cat("Feeding_Type", "Breastmilk", "Breastmilk & Formula") %>% 
  remove_rownames()) %>% 
  rbind(get_deseq_res_cat("Feeding_Type", "Formula", "Breastmilk & Formula") %>% 
  remove_rownames()) %>% 
  rbind(get_deseq_res_cat("NEC") %>% 
  remove_rownames())
```

### Export DESeq2 results 

```{r, eval=F}
tab_df(deseq_model, alternate.rows = TRUE, 
       title = "Significantly Differentially Abundant Taxa", 
       file = "DESeq2_Mixed_Model.doc")
```

### DESeq2 Plots

 - Construct histograms to compare pre and post transformation.
 - Call `estimateDispersions()` to calculate abundances with `getVarianceStabilizedData()`.
 - **NB** piped to `calc_geo_means()` to calculate geometric means and estimate size factors, which is needed for the above.
 - **NB.** the samples are in columns in the *deseq* object but in rows for the *phyloseq* object.
 
**Change `Primary_Group` & `Feeding_Type`.**
```{r, warning=F, message=F, fig.cap="Pre and post transformation of taxonomic counts with DESeq2"}
plot_deseq_transformation <- function(deseq_object){
multi.deseq <- estimateDispersions(deseq_object, fitType = "local")  

abund_sums_trans <- data.frame(sum = colSums(getVarianceStabilizedData(multi.deseq) ), 
                     sample = colnames(getVarianceStabilizedData(multi.deseq) ), 
                     type = "DESeq2")

abund_sums_no_trans <- data.frame(sum = rowSums(otu_table(ps3)), 
                       sample = rownames(otu_table(ps3)), 
                       type = "None")

grid.arrange((ggplot(abund_sums_trans) +
  geom_histogram(aes(x = sum), binwidth = 1) +
  xlab("Abundance within sample") +
  ggtitle("DESeq2 transformation")),
  (ggplot(abund_sums_no_trans) +
  geom_histogram(aes(x = sum), binwidth = 200) +
  xlab("Abundance within sample") +
  ylim(0,4) +
  ggtitle("No transformation")),
  nrow = 2)
}

phyloseq_to_deseq2(ps3, ~ Primary_Group + Feeding_Type) %>% calc_geo_means() %>% plot_deseq_transformation()
```

 - Visualising deseq-transformed abundances with heat maps.

**Change `Primary_Group` & `Feeding_Type`.**
```{r, warning=F, message=F, eval=F}
phyloseq_to_deseq2(ps3, ~ Primary_Group + Feeding_Type) %>% 
    calc_geo_means() %>% 
    deseq_filter() %>% 
    DESeq(fitType = "local", test = "LRT", reduced = ~ Primary_Group) %>%
    varianceStabilizingTransformation() %>%
    assay() %>% 
    cor() %>%
    pheatmap()
```

 - Visualising deseq-transformed abundances with PCA (substitute in any variable).
 
**Change `Mode.of.Delivery`.**
```{r, warning=F, message=F, eval=F}
multi.deseq.clean %>%
  varianceStabilizingTransformation() %>% 
  plotPCA(intgroup = "Mode.of.Delivery") +
   xlim(-20,20)+
   ylim(-20,20)
```


# Mixed effects modelling with glms for alpha diversity

```{r, warning=F, message=F, results='hide'}
sapply(c("lme4", "nlme", "dplyr", "plyr", "lmerTest", "aods3", 
         "tidyverse", "ggplot2", "MuMIn", "sjPlot", "gridExtra", 
         "grid", "car", "emmeans", "ggpubr"), 
         require, character.only = TRUE)
```

## Centre/Scale numerical values

```{r}
glm_data <- centre_and_scale(ps_metadata)
```

### Test for collinearity

**Change variables.**
```{r}
glm_data %>% 
  select(Feeding_Type, NEC, Sepsis, Died, Mode_of_Delivery, Antenatal_Antibiotics, Neonatal_Antibiotics, Chorioamnionitis, Antenatal_Infections, Prolonged_Membrane_Rupture, Diabetes, Preeclampsia, ROP, Birth_Weight, Nursery_Discharge_Weight, Date_Collected, Gestational_Age_at_Birth, Primary_Group, Type) %>% 
  corvif()
```

## Fit Model

**Change fixed and random effects.**
```{r, warning=F, message=F, results='hide'}
global <- lme4::glmer(Shannon ~ Primary_Group + Feedin_Type + (1|URN), data = glm_data) %>% summary()
```



### If convergence issues arise, use [allFit](https://www.rdocumentation.org/packages/lme4/versions/1.1-26/topics/allFit) to see why.

 - If they all work then any non-convergence warning is a false positive.

**Change fixed and random effects.**
```{r}
glmer_refit <- lme4::glmer(Shannon ~ Primary_Group + Feedin_Type + (1|URN), data = glm_data) %>% 
  allFit() %>% 
  summary()

glmer_refit$which.OK # which optimisers work
```

### Calculate the goodness of fit and R2.

 - Calculate this again post bakwards selection.
 
```{r, eval=F}
gof(global)
r.squaredGLMM(global)
```

## Backwards Selection.
 - Define a function that determines what variable is contributing least to the model, as determined by AIC score.
 - Then apply that function to the model, and subsequent models, removing variables from the model that are not contributing (first from the interaction and then from the model entirely).

**Create as many global iterations as needed.**
```{r, warning=F, message=F}
dfun <- function(x) {
  x$AIC <- x$AIC-min(x$AIC)
  names(x)[2] <- "dAIC"
  x
}

dfun(drop1(global))

global2 <- # remove variables from inside interaction, or from model entirely
  
dfun(drop1(global2))
```

### Calculate the goodness of fit and R2.

**Replace model name with final model.**
```{r, eval=F}
gof(global2)
r.squaredGLMM(global2)
```

### QQ-Plot.

**Replace model name with final model.**
```{r, warning=F, message=F}
qqnorm(resid(global2)) 
```

## Reintgeration

 - Add variables from the first model back into the final model one at a time to calculate estimates, SE and p values for each.

**Change fixed effects.**
```{r, message=F, warning=F}
lme4::glmer(Shannon ~ Primary_Group + Feedin_Type + (1|URN), data = glm_data) %>% 
  summary()
```

**FINISIHED** 

[**Link to github repo.**](https://github.com/JacobAFW/SCN_vs_NICU_probiotic_study)
